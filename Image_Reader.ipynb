{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projeto Final de Ciência dos Dados. ( PkmnID)\n",
    "\n",
    "## Algoritmo de predição da categoria de Pokémons por meio de suas imagens.\n",
    "### O algoritmo realiza a extração e a clusterização de features de imagens por meio do método \\\"Bag of Visual Words\\\" (BOVW),classifica-as utilizando o método de machine learning \\\"Random Forest\\\" e prevê a categoria de Pokémons por meio de novas imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.1.26)\nRequirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.15.4)\n"
    }
   ],
   "source": [
    "!pip install opencv-contrib-python\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "TRAIN_DIR = 'Assets/Final/Train_base'\n",
    "SUPER_TRAIN_DIR = 'Assets/Final/Train_super'\n",
    "TEST_DIR = 'Assets/Final/Test'\n",
    "CLASSES = os.listdir(TRAIN_DIR)\n",
    "\n",
    "NUM_CLUSTERS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Máquina de controle:\n",
    "\n",
    "# Re-adquiri as features das imagens.\n",
    "READ_IMAGES = 0\n",
    "\n",
    "# Cria arquivo Json para dicionário de Features.\n",
    "UPDATE_FILES = 0\n",
    "\n",
    "# Constrói dataframe com dados do dicionário de features.\n",
    "CREATE_FEATURE_DATAFRAME = 1\n",
    "\n",
    "# Mostra em quais 'n' pokémons, cada feature é mais proeminente.\n",
    "SHOW_TOP_N_FOR_FEATURES = 1\n",
    "\n",
    "# Re-treina os models.\n",
    "FIT_MODELS = 1\n",
    "\n",
    "# Produz matrizes de confusão para todos os modelos.\n",
    "PLOT_CONFUSION_MATRIXES = 0\n",
    "\n",
    "# Produz uma lista com a métrica precision@n para todos os modelos.\n",
    "PRECISION_AT_N = 0\n",
    "\n",
    "# Roda o modelo combinado dos 3 modelos originais.\n",
    "RUN_SUPER_MODEL = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Extração de features de imagens: Bag of Visual Words\n",
    "### Uma vez que o dataset se trata de um conjunto de imagens de diferentes Pokémons, é necessário inicialmente extrair features dessas imagens, através do método \"Bag of Visual Words\".\n",
    "### Com as imagens transformadas em features clusterizadas, elas são separadas em categorias de treino e teste, que serão utilizadas posteriormente pelo algoritmo de machine learning.\n",
    "### O código abaixo realiza essas duas etapas:\n",
    "#### Obs: Código produzido com a assistência do Prof. Fábio Ayres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_names(TRAIN_DIR = TRAIN_DIR, SUPER_TRAIN_DIR = SUPER_TRAIN_DIR, TEST_DIR = TEST_DIR):\n",
    "\n",
    "    TRAIN_IMG = []\n",
    "    TEST_IMG = []\n",
    "    TRAIN_LABEL = []\n",
    "    TEST_LABEL = []\n",
    "    SUPER_TRAIN_IMG = []\n",
    "    SUPER_TRAIN_LABEL = []\n",
    "\n",
    "    for train, sup_train, test in zip(os.listdir(TRAIN_DIR), os.listdir(SUPER_TRAIN_DIR), os.listdir(TEST_DIR)): \n",
    "        #Tecnicamente são iguais, mas não custa garantir.\n",
    "        dir_train = os.listdir(os.path.join(TRAIN_DIR,train))\n",
    "        dir_sup_train = os.listdir(os.path.join(SUPER_TRAIN_DIR,sup_train))\n",
    "        dir_test = os.listdir(os.path.join(TEST_DIR,test))\n",
    "        for img_train, sup_img_train, img_test in zip(dir_train, dir_sup_train, dir_test):\n",
    "            TRAIN_IMG.append(os.path.join(TRAIN_DIR, train, img_train))\n",
    "            TEST_IMG.append(os.path.join(TEST_DIR, test, img_test))\n",
    "            TRAIN_LABEL.append(train)\n",
    "            TEST_LABEL.append(test)\n",
    "            SUPER_TRAIN_IMG.append(os.path.join(SUPER_TRAIN_DIR, sup_train, sup_img_train))\n",
    "            SUPER_TRAIN_LABEL.append(sup_train)\n",
    "\n",
    "    return TRAIN_IMG, TEST_IMG, SUPER_TRAIN_IMG, SUPER_TRAIN_LABEL, TRAIN_LABEL, TEST_LABEL\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(representa(vocab, img).flatten())\n",
    "    return np.array(X)\n",
    "\n",
    "def show_example(path = os.listdir(\"Testes/Testes/\")[0], plot = True):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, dsize=(120, 120))\n",
    "    if Plot:\n",
    "        plt.imshow(img_resized, cmap='gray', vmin=0, vmax=255)\n",
    "    return representa(vocab, img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dict = {}\n",
    "Test_Dict = {}\n",
    "TRAIN_IMG, TEST_IMG, SUPER_TRAIN_IMG, SUPER_TRAIN_LABEL, TRAIN_LABEL, TEST_LABEL = get_img_names()\n",
    "\n",
    "if READ_IMAGES:       \n",
    "    vocab = cria_vocabulario(TRAIN_IMG, NUM_CLUSTERS)\n",
    "    for pkmn in os.listdir(TRAIN_DIR):\n",
    "        Hist_Dict[pkmn] = transforma_imagens([os.path.join(TRAIN_DIR, pkmn, n) for n in os.listdir(os.path.join(TRAIN_DIR,pkmn))], vocab)   \n",
    "    for pkmn in os.listdir(TEST_DIR):\n",
    "        Test_Dict[pkmn] = transforma_imagens([os.path.join(TEST_DIR, pkmn, n) for n in os.listdir(os.path.join(TEST_DIR,pkmn))], vocab)\n",
    "    \n",
    "    \n",
    "    if UPDATE_FILES:\n",
    "        if 'files' not in os.listdir(\"Assets/\"):\n",
    "            os.mkdir('Assets/files')\n",
    "        np.save('Assets/files/Features_Train', Hist_Dict)\n",
    "        np.save('Assets/files/Features_Test', Test_Dict)\n",
    "        np.save('Assets/files/Bag_of_Visual_Words', vocab)\n",
    "            \n",
    "\n",
    "else:\n",
    "        Hist_Dict = np.load('Assets/files/Features_Train.npy', allow_pickle=True)[()]\n",
    "        Test_Dict = np.load('Assets/files/Features_Test.npy', allow_pickle=True)[()]\n",
    "        vocab = np.load('Assets/files/Bag_of_Visual_Words.npy', allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = np.array([v for k,v in Hist_Dict.items()]) \n",
    "X_test_vectors = np.array([v for k,v in Test_Dict.items()]) \n",
    "y_train_vectors = [] \n",
    "y_test_vectors = []\n",
    "\n",
    "for k in Hist_Dict:\n",
    "    x = []\n",
    "    for v in Hist_Dict[k]:\n",
    "        x.append(k)\n",
    "    x = np.array(x)\n",
    "    y_train_vectors.append(x)\n",
    "\n",
    "\n",
    "for k in Test_Dict:\n",
    "    x2 = []\n",
    "    for v in Test_Dict[k]:\n",
    "        x2.append(k)\n",
    "    x2 = np.array(x2)\n",
    "    y_test_vectors.append(x2)\n",
    "\n",
    "y_train_vectors = np.array(y_train_vectors)\n",
    "y_test_vectors = np.array(y_test_vectors)\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for pkmn, matrix in zip(CLASSES, X_train_vectors):\n",
    "    for feature_vector in matrix:\n",
    "        X_train.append(feature_vector)\n",
    "        y_train.append(pkmn)\n",
    "\n",
    "for pkmn_test, matrix_test in zip(CLASSES, X_test_vectors):\n",
    "    for feature_vector_test in matrix_test:\n",
    "        X_test.append(feature_vector_test)\n",
    "        y_test.append(pkmn_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 - Análise Exploratória:\n",
    "### Para realizar a análise exploratória seguiremos alguns passos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2 - Criar um dataframe para trabalhar melhor com o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_FEATURE_DATAFRAME:    \n",
    "    lista = []\n",
    "    for k in Hist_Dict:\n",
    "        mean = []\n",
    "        for i in range(NUM_CLUSTERS):\n",
    "            mean.append(pd.Series(Hist_Dict[k][:,i]).mean())\n",
    "        lista.append(mean)\n",
    "    df_medias = pd.DataFrame(lista, index = CLASSES)\n",
    "else:\n",
    "    df_medias = pd.DataFrame([[1],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tabela das frequências relativas médias de cada feature por pokémon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Aerodactyl</th>\n      <td>0.044075</td>\n      <td>0.036230</td>\n      <td>0.023366</td>\n      <td>0.033021</td>\n      <td>0.023688</td>\n      <td>0.102180</td>\n      <td>0.032040</td>\n      <td>0.005423</td>\n      <td>0.016188</td>\n      <td>0.060155</td>\n      <td>...</td>\n      <td>0.012572</td>\n      <td>0.024531</td>\n      <td>0.025768</td>\n      <td>0.011084</td>\n      <td>0.006088</td>\n      <td>0.029070</td>\n      <td>0.033695</td>\n      <td>0.025318</td>\n      <td>0.023531</td>\n      <td>0.102536</td>\n    </tr>\n    <tr>\n      <th>Alakazam</th>\n      <td>0.042203</td>\n      <td>0.071594</td>\n      <td>0.019158</td>\n      <td>0.046033</td>\n      <td>0.032938</td>\n      <td>0.054789</td>\n      <td>0.030445</td>\n      <td>0.006991</td>\n      <td>0.019175</td>\n      <td>0.041339</td>\n      <td>...</td>\n      <td>0.010976</td>\n      <td>0.035718</td>\n      <td>0.045208</td>\n      <td>0.005365</td>\n      <td>0.009104</td>\n      <td>0.027694</td>\n      <td>0.020182</td>\n      <td>0.033983</td>\n      <td>0.029512</td>\n      <td>0.046339</td>\n    </tr>\n    <tr>\n      <th>Arbok</th>\n      <td>0.021487</td>\n      <td>0.036324</td>\n      <td>0.050306</td>\n      <td>0.020419</td>\n      <td>0.026035</td>\n      <td>0.029829</td>\n      <td>0.025081</td>\n      <td>0.014049</td>\n      <td>0.015443</td>\n      <td>0.019430</td>\n      <td>...</td>\n      <td>0.016183</td>\n      <td>0.014349</td>\n      <td>0.020465</td>\n      <td>0.084399</td>\n      <td>0.014313</td>\n      <td>0.008742</td>\n      <td>0.013688</td>\n      <td>0.022960</td>\n      <td>0.022318</td>\n      <td>0.030259</td>\n    </tr>\n    <tr>\n      <th>Arcanine</th>\n      <td>0.030450</td>\n      <td>0.041339</td>\n      <td>0.037431</td>\n      <td>0.043823</td>\n      <td>0.028322</td>\n      <td>0.022084</td>\n      <td>0.023125</td>\n      <td>0.009938</td>\n      <td>0.018811</td>\n      <td>0.028991</td>\n      <td>...</td>\n      <td>0.012259</td>\n      <td>0.028663</td>\n      <td>0.036785</td>\n      <td>0.018080</td>\n      <td>0.011499</td>\n      <td>0.030481</td>\n      <td>0.026166</td>\n      <td>0.045413</td>\n      <td>0.042705</td>\n      <td>0.014914</td>\n    </tr>\n    <tr>\n      <th>Beedrill</th>\n      <td>0.045788</td>\n      <td>0.052127</td>\n      <td>0.015594</td>\n      <td>0.029527</td>\n      <td>0.023490</td>\n      <td>0.057362</td>\n      <td>0.020623</td>\n      <td>0.003705</td>\n      <td>0.016917</td>\n      <td>0.029218</td>\n      <td>...</td>\n      <td>0.009918</td>\n      <td>0.036671</td>\n      <td>0.037900</td>\n      <td>0.008291</td>\n      <td>0.005948</td>\n      <td>0.041655</td>\n      <td>0.036905</td>\n      <td>0.045640</td>\n      <td>0.048834</td>\n      <td>0.049458</td>\n    </tr>\n    <tr>\n      <th>Bellsprout</th>\n      <td>0.010190</td>\n      <td>0.025281</td>\n      <td>0.023933</td>\n      <td>0.056161</td>\n      <td>0.031274</td>\n      <td>0.027047</td>\n      <td>0.017095</td>\n      <td>0.008400</td>\n      <td>0.017391</td>\n      <td>0.029988</td>\n      <td>...</td>\n      <td>0.005172</td>\n      <td>0.049062</td>\n      <td>0.032132</td>\n      <td>0.009053</td>\n      <td>0.008097</td>\n      <td>0.056463</td>\n      <td>0.051991</td>\n      <td>0.060806</td>\n      <td>0.041321</td>\n      <td>0.020776</td>\n    </tr>\n    <tr>\n      <th>Bulbasaur</th>\n      <td>0.038257</td>\n      <td>0.039303</td>\n      <td>0.057396</td>\n      <td>0.036865</td>\n      <td>0.018234</td>\n      <td>0.018575</td>\n      <td>0.025118</td>\n      <td>0.006608</td>\n      <td>0.020509</td>\n      <td>0.029396</td>\n      <td>...</td>\n      <td>0.025432</td>\n      <td>0.014796</td>\n      <td>0.020394</td>\n      <td>0.047251</td>\n      <td>0.011836</td>\n      <td>0.006658</td>\n      <td>0.007208</td>\n      <td>0.020668</td>\n      <td>0.019306</td>\n      <td>0.009178</td>\n    </tr>\n    <tr>\n      <th>Charmander</th>\n      <td>0.030880</td>\n      <td>0.017806</td>\n      <td>0.038978</td>\n      <td>0.023512</td>\n      <td>0.035953</td>\n      <td>0.038134</td>\n      <td>0.019550</td>\n      <td>0.006893</td>\n      <td>0.034240</td>\n      <td>0.039148</td>\n      <td>...</td>\n      <td>0.018101</td>\n      <td>0.019170</td>\n      <td>0.030615</td>\n      <td>0.037461</td>\n      <td>0.008151</td>\n      <td>0.019516</td>\n      <td>0.027197</td>\n      <td>0.034926</td>\n      <td>0.032833</td>\n      <td>0.034143</td>\n    </tr>\n    <tr>\n      <th>Jigglypuff</th>\n      <td>0.021146</td>\n      <td>0.029880</td>\n      <td>0.025263</td>\n      <td>0.065154</td>\n      <td>0.017972</td>\n      <td>0.016600</td>\n      <td>0.022263</td>\n      <td>0.007698</td>\n      <td>0.012020</td>\n      <td>0.019170</td>\n      <td>...</td>\n      <td>0.021365</td>\n      <td>0.032932</td>\n      <td>0.035000</td>\n      <td>0.018608</td>\n      <td>0.009220</td>\n      <td>0.037777</td>\n      <td>0.025420</td>\n      <td>0.036577</td>\n      <td>0.038040</td>\n      <td>0.012375</td>\n    </tr>\n    <tr>\n      <th>Meowth</th>\n      <td>0.034858</td>\n      <td>0.043058</td>\n      <td>0.017794</td>\n      <td>0.047876</td>\n      <td>0.028052</td>\n      <td>0.029387</td>\n      <td>0.019585</td>\n      <td>0.008609</td>\n      <td>0.014159</td>\n      <td>0.046917</td>\n      <td>...</td>\n      <td>0.008856</td>\n      <td>0.041095</td>\n      <td>0.044787</td>\n      <td>0.007415</td>\n      <td>0.011203</td>\n      <td>0.043575</td>\n      <td>0.028548</td>\n      <td>0.031875</td>\n      <td>0.034071</td>\n      <td>0.024253</td>\n    </tr>\n    <tr>\n      <th>Pidgey</th>\n      <td>0.034924</td>\n      <td>0.021526</td>\n      <td>0.030966</td>\n      <td>0.026635</td>\n      <td>0.028571</td>\n      <td>0.046532</td>\n      <td>0.017937</td>\n      <td>0.005405</td>\n      <td>0.018607</td>\n      <td>0.041045</td>\n      <td>...</td>\n      <td>0.011445</td>\n      <td>0.024966</td>\n      <td>0.023555</td>\n      <td>0.021958</td>\n      <td>0.007956</td>\n      <td>0.033669</td>\n      <td>0.042238</td>\n      <td>0.042786</td>\n      <td>0.046469</td>\n      <td>0.032586</td>\n    </tr>\n    <tr>\n      <th>Squirtle</th>\n      <td>0.032085</td>\n      <td>0.035233</td>\n      <td>0.048693</td>\n      <td>0.041044</td>\n      <td>0.036636</td>\n      <td>0.021376</td>\n      <td>0.014086</td>\n      <td>0.004939</td>\n      <td>0.021962</td>\n      <td>0.028409</td>\n      <td>...</td>\n      <td>0.007596</td>\n      <td>0.021069</td>\n      <td>0.032474</td>\n      <td>0.039598</td>\n      <td>0.008682</td>\n      <td>0.023921</td>\n      <td>0.028730</td>\n      <td>0.045932</td>\n      <td>0.044389</td>\n      <td>0.014769</td>\n    </tr>\n    <tr>\n      <th>Voltorb</th>\n      <td>0.021237</td>\n      <td>0.024704</td>\n      <td>0.027343</td>\n      <td>0.013246</td>\n      <td>0.007403</td>\n      <td>0.072509</td>\n      <td>0.026233</td>\n      <td>0.009482</td>\n      <td>0.007512</td>\n      <td>0.036727</td>\n      <td>...</td>\n      <td>0.015125</td>\n      <td>0.005905</td>\n      <td>0.005937</td>\n      <td>0.103159</td>\n      <td>0.011424</td>\n      <td>0.009081</td>\n      <td>0.028892</td>\n      <td>0.034634</td>\n      <td>0.026500</td>\n      <td>0.076787</td>\n    </tr>\n  </tbody>\n</table>\n<p>13 rows × 40 columns</p>\n</div>",
      "text/plain": "                  0         1         2         3         4         5   \\\nAerodactyl  0.044075  0.036230  0.023366  0.033021  0.023688  0.102180   \nAlakazam    0.042203  0.071594  0.019158  0.046033  0.032938  0.054789   \nArbok       0.021487  0.036324  0.050306  0.020419  0.026035  0.029829   \nArcanine    0.030450  0.041339  0.037431  0.043823  0.028322  0.022084   \nBeedrill    0.045788  0.052127  0.015594  0.029527  0.023490  0.057362   \nBellsprout  0.010190  0.025281  0.023933  0.056161  0.031274  0.027047   \nBulbasaur   0.038257  0.039303  0.057396  0.036865  0.018234  0.018575   \nCharmander  0.030880  0.017806  0.038978  0.023512  0.035953  0.038134   \nJigglypuff  0.021146  0.029880  0.025263  0.065154  0.017972  0.016600   \nMeowth      0.034858  0.043058  0.017794  0.047876  0.028052  0.029387   \nPidgey      0.034924  0.021526  0.030966  0.026635  0.028571  0.046532   \nSquirtle    0.032085  0.035233  0.048693  0.041044  0.036636  0.021376   \nVoltorb     0.021237  0.024704  0.027343  0.013246  0.007403  0.072509   \n\n                  6         7         8         9     ...           30  \\\nAerodactyl  0.032040  0.005423  0.016188  0.060155    ...     0.012572   \nAlakazam    0.030445  0.006991  0.019175  0.041339    ...     0.010976   \nArbok       0.025081  0.014049  0.015443  0.019430    ...     0.016183   \nArcanine    0.023125  0.009938  0.018811  0.028991    ...     0.012259   \nBeedrill    0.020623  0.003705  0.016917  0.029218    ...     0.009918   \nBellsprout  0.017095  0.008400  0.017391  0.029988    ...     0.005172   \nBulbasaur   0.025118  0.006608  0.020509  0.029396    ...     0.025432   \nCharmander  0.019550  0.006893  0.034240  0.039148    ...     0.018101   \nJigglypuff  0.022263  0.007698  0.012020  0.019170    ...     0.021365   \nMeowth      0.019585  0.008609  0.014159  0.046917    ...     0.008856   \nPidgey      0.017937  0.005405  0.018607  0.041045    ...     0.011445   \nSquirtle    0.014086  0.004939  0.021962  0.028409    ...     0.007596   \nVoltorb     0.026233  0.009482  0.007512  0.036727    ...     0.015125   \n\n                  31        32        33        34        35        36  \\\nAerodactyl  0.024531  0.025768  0.011084  0.006088  0.029070  0.033695   \nAlakazam    0.035718  0.045208  0.005365  0.009104  0.027694  0.020182   \nArbok       0.014349  0.020465  0.084399  0.014313  0.008742  0.013688   \nArcanine    0.028663  0.036785  0.018080  0.011499  0.030481  0.026166   \nBeedrill    0.036671  0.037900  0.008291  0.005948  0.041655  0.036905   \nBellsprout  0.049062  0.032132  0.009053  0.008097  0.056463  0.051991   \nBulbasaur   0.014796  0.020394  0.047251  0.011836  0.006658  0.007208   \nCharmander  0.019170  0.030615  0.037461  0.008151  0.019516  0.027197   \nJigglypuff  0.032932  0.035000  0.018608  0.009220  0.037777  0.025420   \nMeowth      0.041095  0.044787  0.007415  0.011203  0.043575  0.028548   \nPidgey      0.024966  0.023555  0.021958  0.007956  0.033669  0.042238   \nSquirtle    0.021069  0.032474  0.039598  0.008682  0.023921  0.028730   \nVoltorb     0.005905  0.005937  0.103159  0.011424  0.009081  0.028892   \n\n                  37        38        39  \nAerodactyl  0.025318  0.023531  0.102536  \nAlakazam    0.033983  0.029512  0.046339  \nArbok       0.022960  0.022318  0.030259  \nArcanine    0.045413  0.042705  0.014914  \nBeedrill    0.045640  0.048834  0.049458  \nBellsprout  0.060806  0.041321  0.020776  \nBulbasaur   0.020668  0.019306  0.009178  \nCharmander  0.034926  0.032833  0.034143  \nJigglypuff  0.036577  0.038040  0.012375  \nMeowth      0.031875  0.034071  0.024253  \nPidgey      0.042786  0.046469  0.032586  \nSquirtle    0.045932  0.044389  0.014769  \nVoltorb     0.034634  0.026500  0.076787  \n\n[13 rows x 40 columns]"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3 - Calculando os valores médios dos dados:\n",
    "### Nesta etapa foi calculado os valores médios dos dados, e em sequência foram aproximados do ponto (0,0), origem do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias = df_medias - (1/NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Aerodactyl    1.480803e-07\nAlakazam      1.266599e-07\nArbok         1.131557e-07\nArcanine      1.103617e-07\nBeedrill     -1.140870e-08\nBellsprout    7.683411e-08\nBulbasaur    -2.281740e-08\nCharmander    1.410954e-07\nJigglypuff    4.190952e-09\nMeowth       -9.313226e-10\nPidgey        1.015142e-07\nSquirtle      1.615845e-07\nVoltorb      -1.168810e-07\ndtype: float64"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medias.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "normas = (df_medias*df_medias).sum(axis=1)\n",
    "for m in normas.index:\n",
    "    df_medias.loc[m] = df_medias.loc[m]/np.sqrt(normas[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 - Comparação entre os Pokémons:\n",
    "### Com base nos valores calculados anteriormente, foi criada a tabela seguinte, que mostra o quanto os Pokémons são semelhantes entre si, sendo 1 a semelhança máxima, e -1 o oposto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Aerodactyl</th>\n      <th>Alakazam</th>\n      <th>Arbok</th>\n      <th>Arcanine</th>\n      <th>Beedrill</th>\n      <th>Bellsprout</th>\n      <th>Bulbasaur</th>\n      <th>Charmander</th>\n      <th>Jigglypuff</th>\n      <th>Meowth</th>\n      <th>Pidgey</th>\n      <th>Squirtle</th>\n      <th>Voltorb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Aerodactyl</th>\n      <td>1.000000</td>\n      <td>0.702084</td>\n      <td>0.092649</td>\n      <td>0.284312</td>\n      <td>0.706093</td>\n      <td>0.275357</td>\n      <td>-0.048073</td>\n      <td>0.421713</td>\n      <td>0.056577</td>\n      <td>0.439771</td>\n      <td>0.560301</td>\n      <td>0.208436</td>\n      <td>0.437440</td>\n    </tr>\n    <tr>\n      <th>Alakazam</th>\n      <td>0.702084</td>\n      <td>1.000000</td>\n      <td>0.190372</td>\n      <td>0.659588</td>\n      <td>0.793147</td>\n      <td>0.445378</td>\n      <td>0.075146</td>\n      <td>0.277080</td>\n      <td>0.235179</td>\n      <td>0.698492</td>\n      <td>0.449811</td>\n      <td>0.442211</td>\n      <td>0.103099</td>\n    </tr>\n    <tr>\n      <th>Arbok</th>\n      <td>0.092649</td>\n      <td>0.190372</td>\n      <td>1.000000</td>\n      <td>0.340027</td>\n      <td>0.095485</td>\n      <td>-0.127736</td>\n      <td>0.564565</td>\n      <td>0.345506</td>\n      <td>-0.021403</td>\n      <td>0.002739</td>\n      <td>0.131951</td>\n      <td>0.478960</td>\n      <td>0.599455</td>\n    </tr>\n    <tr>\n      <th>Arcanine</th>\n      <td>0.284312</td>\n      <td>0.659588</td>\n      <td>0.340027</td>\n      <td>1.000000</td>\n      <td>0.735642</td>\n      <td>0.602886</td>\n      <td>0.369396</td>\n      <td>0.497430</td>\n      <td>0.540171</td>\n      <td>0.725805</td>\n      <td>0.666950</td>\n      <td>0.862296</td>\n      <td>0.090724</td>\n    </tr>\n    <tr>\n      <th>Beedrill</th>\n      <td>0.706093</td>\n      <td>0.793147</td>\n      <td>0.095485</td>\n      <td>0.735642</td>\n      <td>1.000000</td>\n      <td>0.579947</td>\n      <td>0.107189</td>\n      <td>0.475230</td>\n      <td>0.363180</td>\n      <td>0.727374</td>\n      <td>0.743031</td>\n      <td>0.544686</td>\n      <td>0.274503</td>\n    </tr>\n    <tr>\n      <th>Bellsprout</th>\n      <td>0.275357</td>\n      <td>0.445378</td>\n      <td>-0.127736</td>\n      <td>0.602886</td>\n      <td>0.579947</td>\n      <td>1.000000</td>\n      <td>-0.170264</td>\n      <td>0.290983</td>\n      <td>0.707500</td>\n      <td>0.734042</td>\n      <td>0.553396</td>\n      <td>0.533618</td>\n      <td>-0.017376</td>\n    </tr>\n    <tr>\n      <th>Bulbasaur</th>\n      <td>-0.048073</td>\n      <td>0.075146</td>\n      <td>0.564565</td>\n      <td>0.369396</td>\n      <td>0.107189</td>\n      <td>-0.170264</td>\n      <td>1.000000</td>\n      <td>0.591847</td>\n      <td>0.252955</td>\n      <td>0.241852</td>\n      <td>0.361455</td>\n      <td>0.530171</td>\n      <td>0.514097</td>\n    </tr>\n    <tr>\n      <th>Charmander</th>\n      <td>0.421713</td>\n      <td>0.277080</td>\n      <td>0.345506</td>\n      <td>0.497430</td>\n      <td>0.475230</td>\n      <td>0.290983</td>\n      <td>0.591847</td>\n      <td>1.000000</td>\n      <td>0.444750</td>\n      <td>0.543096</td>\n      <td>0.827574</td>\n      <td>0.739806</td>\n      <td>0.627000</td>\n    </tr>\n    <tr>\n      <th>Jigglypuff</th>\n      <td>0.056577</td>\n      <td>0.235179</td>\n      <td>-0.021403</td>\n      <td>0.540171</td>\n      <td>0.363180</td>\n      <td>0.707500</td>\n      <td>0.252955</td>\n      <td>0.444750</td>\n      <td>1.000000</td>\n      <td>0.698497</td>\n      <td>0.505420</td>\n      <td>0.586286</td>\n      <td>0.170074</td>\n    </tr>\n    <tr>\n      <th>Meowth</th>\n      <td>0.439771</td>\n      <td>0.698492</td>\n      <td>0.002739</td>\n      <td>0.725805</td>\n      <td>0.727374</td>\n      <td>0.734042</td>\n      <td>0.241852</td>\n      <td>0.543096</td>\n      <td>0.698497</td>\n      <td>1.000000</td>\n      <td>0.742866</td>\n      <td>0.639660</td>\n      <td>0.145789</td>\n    </tr>\n    <tr>\n      <th>Pidgey</th>\n      <td>0.560301</td>\n      <td>0.449811</td>\n      <td>0.131951</td>\n      <td>0.666950</td>\n      <td>0.743031</td>\n      <td>0.553396</td>\n      <td>0.361455</td>\n      <td>0.827574</td>\n      <td>0.505420</td>\n      <td>0.742866</td>\n      <td>1.000000</td>\n      <td>0.729352</td>\n      <td>0.457227</td>\n    </tr>\n    <tr>\n      <th>Squirtle</th>\n      <td>0.208436</td>\n      <td>0.442211</td>\n      <td>0.478960</td>\n      <td>0.862296</td>\n      <td>0.544686</td>\n      <td>0.533618</td>\n      <td>0.530171</td>\n      <td>0.739806</td>\n      <td>0.586286</td>\n      <td>0.639660</td>\n      <td>0.729352</td>\n      <td>1.000000</td>\n      <td>0.324094</td>\n    </tr>\n    <tr>\n      <th>Voltorb</th>\n      <td>0.437440</td>\n      <td>0.103099</td>\n      <td>0.599455</td>\n      <td>0.090724</td>\n      <td>0.274503</td>\n      <td>-0.017376</td>\n      <td>0.514097</td>\n      <td>0.627000</td>\n      <td>0.170074</td>\n      <td>0.145789</td>\n      <td>0.457227</td>\n      <td>0.324094</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            Aerodactyl  Alakazam     Arbok  Arcanine  Beedrill  Bellsprout  \\\nAerodactyl    1.000000  0.702084  0.092649  0.284312  0.706093    0.275357   \nAlakazam      0.702084  1.000000  0.190372  0.659588  0.793147    0.445378   \nArbok         0.092649  0.190372  1.000000  0.340027  0.095485   -0.127736   \nArcanine      0.284312  0.659588  0.340027  1.000000  0.735642    0.602886   \nBeedrill      0.706093  0.793147  0.095485  0.735642  1.000000    0.579947   \nBellsprout    0.275357  0.445378 -0.127736  0.602886  0.579947    1.000000   \nBulbasaur    -0.048073  0.075146  0.564565  0.369396  0.107189   -0.170264   \nCharmander    0.421713  0.277080  0.345506  0.497430  0.475230    0.290983   \nJigglypuff    0.056577  0.235179 -0.021403  0.540171  0.363180    0.707500   \nMeowth        0.439771  0.698492  0.002739  0.725805  0.727374    0.734042   \nPidgey        0.560301  0.449811  0.131951  0.666950  0.743031    0.553396   \nSquirtle      0.208436  0.442211  0.478960  0.862296  0.544686    0.533618   \nVoltorb       0.437440  0.103099  0.599455  0.090724  0.274503   -0.017376   \n\n            Bulbasaur  Charmander  Jigglypuff    Meowth    Pidgey  Squirtle  \\\nAerodactyl  -0.048073    0.421713    0.056577  0.439771  0.560301  0.208436   \nAlakazam     0.075146    0.277080    0.235179  0.698492  0.449811  0.442211   \nArbok        0.564565    0.345506   -0.021403  0.002739  0.131951  0.478960   \nArcanine     0.369396    0.497430    0.540171  0.725805  0.666950  0.862296   \nBeedrill     0.107189    0.475230    0.363180  0.727374  0.743031  0.544686   \nBellsprout  -0.170264    0.290983    0.707500  0.734042  0.553396  0.533618   \nBulbasaur    1.000000    0.591847    0.252955  0.241852  0.361455  0.530171   \nCharmander   0.591847    1.000000    0.444750  0.543096  0.827574  0.739806   \nJigglypuff   0.252955    0.444750    1.000000  0.698497  0.505420  0.586286   \nMeowth       0.241852    0.543096    0.698497  1.000000  0.742866  0.639660   \nPidgey       0.361455    0.827574    0.505420  0.742866  1.000000  0.729352   \nSquirtle     0.530171    0.739806    0.586286  0.639660  0.729352  1.000000   \nVoltorb      0.514097    0.627000    0.170074  0.145789  0.457227  0.324094   \n\n             Voltorb  \nAerodactyl  0.437440  \nAlakazam    0.103099  \nArbok       0.599455  \nArcanine    0.090724  \nBeedrill    0.274503  \nBellsprout -0.017376  \nBulbasaur   0.514097  \nCharmander  0.627000  \nJigglypuff  0.170074  \nMeowth      0.145789  \nPidgey      0.457227  \nSquirtle    0.324094  \nVoltorb     1.000000  "
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compara = df_medias.dot(df_medias.transpose())\n",
    "df_compara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Podemos observar que alguns Pokémons possuem muitas semelhanças pois apresentam as mesmas features em abundância (na média).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[['Aerodactyl', 'Alakazam', 'Arbok', 'Bulbasaur', 'Voltorb', 6],\n ['Aerodactyl', 'Alakazam', 'Beedrill', 'Bulbasaur', 'Pidgey', 0],\n ['Aerodactyl', 'Alakazam', 'Beedrill', 'Charmander', 'Voltorb', 39],\n ['Aerodactyl', 'Alakazam', 'Beedrill', 'Pidgey', 'Voltorb', 5],\n ['Aerodactyl', 'Alakazam', 'Bellsprout', 'Bulbasaur', 'Voltorb', 16],\n ['Aerodactyl', 'Alakazam', 'Bulbasaur', 'Charmander', 'Squirtle', 8],\n ['Aerodactyl', 'Alakazam', 'Bulbasaur', 'Charmander', 'Voltorb', 21],\n ['Aerodactyl', 'Alakazam', 'Bulbasaur', 'Jigglypuff', 'Voltorb', 24],\n ['Aerodactyl', 'Alakazam', 'Charmander', 'Meowth', 'Pidgey', 9],\n ['Aerodactyl', 'Arbok', 'Bellsprout', 'Bulbasaur', 'Voltorb', 12],\n ['Aerodactyl', 'Arbok', 'Bellsprout', 'Bulbasaur', 'Voltorb', 27],\n ['Aerodactyl', 'Arbok', 'Bellsprout', 'Jigglypuff', 'Voltorb', 7],\n ['Aerodactyl', 'Arbok', 'Bellsprout', 'Jigglypuff', 'Voltorb', 28],\n ['Aerodactyl', 'Arbok', 'Bulbasaur', 'Jigglypuff', 'Voltorb', 34],\n ['Aerodactyl', 'Beedrill', 'Bellsprout', 'Pidgey', 'Squirtle', 36],\n ['Aerodactyl', 'Bulbasaur', 'Charmander', 'Jigglypuff', 'Voltorb', 23],\n ['Aerodactyl', 'Bulbasaur', 'Charmander', 'Jigglypuff', 'Voltorb', 30],\n ['Alakazam', 'Arbok', 'Arcanine', 'Beedrill', 'Squirtle', 13],\n ['Alakazam', 'Arbok', 'Arcanine', 'Meowth', 'Squirtle', 19],\n ['Alakazam', 'Arcanine', 'Beedrill', 'Bulbasaur', 'Meowth', 1],\n ['Alakazam', 'Arcanine', 'Beedrill', 'Meowth', 'Squirtle', 32],\n ['Alakazam', 'Arcanine', 'Bellsprout', 'Charmander', 'Squirtle', 4],\n ['Alakazam', 'Arcanine', 'Bellsprout', 'Jigglypuff', 'Meowth', 3],\n ['Alakazam', 'Beedrill', 'Bellsprout', 'Jigglypuff', 'Meowth', 31],\n ['Arbok', 'Arcanine', 'Bellsprout', 'Bulbasaur', 'Voltorb', 20],\n ['Arbok', 'Arcanine', 'Bulbasaur', 'Charmander', 'Squirtle', 2],\n ['Arbok', 'Arcanine', 'Bulbasaur', 'Jigglypuff', 'Voltorb', 14],\n ['Arbok', 'Bellsprout', 'Bulbasaur', 'Squirtle', 'Voltorb', 29],\n ['Arbok', 'Bulbasaur', 'Charmander', 'Squirtle', 'Voltorb', 33],\n ['Arbok', 'Bulbasaur', 'Jigglypuff', 'Meowth', 'Voltorb', 22],\n ['Arbok', 'Charmander', 'Meowth', 'Pidgey', 'Squirtle', 26],\n ['Arcanine', 'Beedrill', 'Bellsprout', 'Pidgey', 'Squirtle', 37],\n ['Arcanine', 'Beedrill', 'Bellsprout', 'Pidgey', 'Squirtle', 38],\n ['Arcanine', 'Beedrill', 'Bulbasaur', 'Charmander', 'Squirtle', 18],\n ['Arcanine', 'Bulbasaur', 'Charmander', 'Pidgey', 'Squirtle', 25],\n ['Beedrill', 'Bellsprout', 'Jigglypuff', 'Meowth', 'Pidgey', 17],\n ['Beedrill', 'Bellsprout', 'Jigglypuff', 'Meowth', 'Pidgey', 35],\n ['Beedrill', 'Bulbasaur', 'Charmander', 'Meowth', 'Pidgey', 10],\n ['Bellsprout', 'Charmander', 'Jigglypuff', 'Meowth', 'Squirtle', 15],\n ['Bulbasaur', 'Charmander', 'Jigglypuff', 'Pidgey', 'Voltorb', 11]]\n"
    }
   ],
   "source": [
    "if SHOW_TOP_N_FOR_FEATURES:    \n",
    "    monstros = []\n",
    "    for feat in range(NUM_CLUSTERS):\n",
    "        monstros.append(sorted(df_medias.nlargest(n=5, columns=[feat]).index) + [feat])\n",
    "    x = sorted(monstros)\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A soma das colunas da tabela anterior mostra quais Pokémons são mais difíceis de distinguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Pidgey        7.729333\nSquirtle      7.619577\nArcanine      7.375228\nMeowth        7.339984\nBeedrill      7.145508\nCharmander    7.082016\nAlakazam      6.071588\nJigglypuff    5.539187\nBellsprout    5.407731\nAerodactyl    5.136662\nVoltorb       4.726126\nBulbasaur     4.390337\nArbok         3.692570\ndtype: float64"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compara.sum(axis = 1).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 - \"Machine Learning\" e Classificação:\n",
    "### O método de aprendizado de máquina e classificação utilizado foi o \"Random Forest Classifier\", assim como \"Logistic Regression Classifier\" e \"KNearesNeighbors Classifier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODELS:\n",
    "    # Random forest\n",
    "    randf = RandomForestClassifier(n_jobs=-1, random_state=0, n_estimators = 100)\n",
    "    randf.fit(X_train, y_train)\n",
    "\n",
    "    # KNearestNeighbors\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    \n",
    "    # Decision Tree\n",
    "    tree = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # Logistic regression, não utilizado.\n",
    "    #logit = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train, y_train)\n",
    "    #logit.fit(X_train, y_train);\n",
    "\n",
    "    # Método Nearest Centroid, não utilizado.\n",
    "    # from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "    # clf4 = NearestCentroid()\n",
    "    # clf4.fit(X_train, y_train)\n",
    "\n",
    "    # Método Support Vector Machine, não utilizado.\n",
    "    # from sklearn import svm\n",
    "    # clf5 = svm.SVC(gamma='scale')\n",
    "    # clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Abaixo armazenamos os modelos numa estrutura que nos será mais acessível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODELS:\n",
    "    models = {'Random Forest': randf,\n",
    "            'KNearestNeighbors': neigh,\n",
    "            'Decision Tree': tree}\n",
    "else:\n",
    "    models = {0:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 - Análise das classificações realizadas pelo modelo:\n",
    "### A matriz de confusão abaixo mostra em mais detalhes os erros e acertos do classificador. É possível identificar que na maioria das vezes que o modelo falhou, ele identificou erroneamente o Pokémon como sendo uma \"Jigglypuff\" ou um \"Arcanine\".\n",
    "\n",
    "#### Obs: A função *plot_confusion_matrix* abaixo não é de nossa autoria, e sua versão original pode ser encontrada no seguinte endereço: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,16))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def multi_confusion_mtx(X_test, y_test, model_dict):\n",
    "    for k,v in model_dict.items():\n",
    "        plot_confusion_matrix(y_test, v.predict(X_test), classes=v.classes_,\n",
    "                            title='Normalized confusion matrix for model %s' % k)\n",
    "        plt.show()\n",
    "\n",
    "def precision_at_n(model, vocab = vocab):\n",
    "    hits, miss = 0, 0\n",
    "    for img, label in zip(TEST_IMG, TEST_LABEL):\n",
    "        rep = representa(vocab, cv2.imread(img))\n",
    "        top3 = pd.Series(model.predict_proba(rep)[0], index = os.listdir('Assets/Data_Test')).nlargest(3)\n",
    "        if label in top3.index.tolist():\n",
    "            hits += 1\n",
    "        else:\n",
    "            miss += 1\n",
    "            \n",
    "    return hits, miss, hits/(hits+miss)\n",
    "\n",
    "def show_guess(path, model):\n",
    "    return pd.Series(model.predict_proba(show_example(path))[0], index = model.classes_).sort_values(ascending = False)\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_CONFUSION_MATRIXES and FIT_MODELS:\n",
    "    multi_confusion_mtx(X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRECISION_AT_N and FIT_MODELS:\n",
    "    pprint({model_name: precision_at_n(model) for (model_name, model) in models.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Random Forest score of: 0.61993\nKNearestNeighbors score of: 0.60424\nDecision Tree score of: 0.47509\n"
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(\"%s score of: %.5f\" % (model_name, model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nada mal! Mas podemos fazer melhor?\n",
    "\n",
    "## Stacking: Combinando os modelos em um(a) supermodelo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}