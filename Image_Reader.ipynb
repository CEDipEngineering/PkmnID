{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de \"Bag of Visual Words\"\n",
    "\n",
    "Vocês estão recebendo este código do professor e devem dar o crédito devido, para que não se caracterize a situação de tentar passar esforço dos outros como sendo seu (a.k.a. plágio). Divirtam-se!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "CATEGORY_LIST = ['Aerodactyl', 'Abra']\n",
    "NUM_IMAGES_TRAIN_PER_CATEGORY = 30\n",
    "NUM_IMAGES_TEST_PER_CATEGORY = 15\n",
    "NUM_CLUSTERS = 300\n",
    "\n",
    "def get_images_from_category(category, num_train, num_test, data_dir):\n",
    "    category_dir = os.path.join(DATA_DIR, category)\n",
    "    num_total = num_train + num_test\n",
    "    filenames_train = []\n",
    "    filenames_test = []\n",
    "    for k, filename in enumerate(os.listdir(category_dir)):\n",
    "        if k < num_train:\n",
    "            filenames_train.append(os.path.join(category_dir, filename))\n",
    "        elif k < num_total:\n",
    "            filenames_test.append(os.path.join(category_dir, filename))\n",
    "        else:\n",
    "            break\n",
    "    return filenames_train, filenames_test\n",
    "\n",
    "def get_images_from_category_list(category_list, num_train, num_test, data_dir):\n",
    "    filenames_train_all = []\n",
    "    filenames_test_all = []\n",
    "    for category in category_list:\n",
    "        filenames_train, filenames_test = get_images_from_category(category, num_train, num_test, data_dir)\n",
    "        filenames_train_all.extend(filenames_train)\n",
    "        filenames_test_all.extend(filenames_test)\n",
    "    return filenames_train_all, filenames_test_all\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(representa(vocab, img).flatten())\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_train, imagens_test = get_images_from_category_list(CATEGORY_LIST, \n",
    "                                                            NUM_IMAGES_TRAIN_PER_CATEGORY, \n",
    "                                                            NUM_IMAGES_TEST_PER_CATEGORY, \n",
    "                                                            DATA_DIR)\n",
    "vocab = cria_vocabulario(imagens_train, NUM_CLUSTERS)\n",
    "X_train = transforma_imagens(imagens_train, vocab)\n",
    "X_test = transforma_imagens(imagens_test, vocab)\n",
    "y_train = np.hstack([np.ones(NUM_IMAGES_TRAIN_PER_CATEGORY), -np.ones(NUM_IMAGES_TRAIN_PER_CATEGORY)])\n",
    "y_test = np.hstack([np.ones(NUM_IMAGES_TEST_PER_CATEGORY), -np.ones(NUM_IMAGES_TEST_PER_CATEGORY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 300)\n",
      "(27, 300)\n",
      "(60,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressione qualquer tecla para continuar.\n",
      "[[0.         0.         0.         0.         0.00598802 0.\n",
      "  0.         0.         0.00299401 0.00598802 0.00598802 0.00299401\n",
      "  0.01197605 0.00299401 0.00299401 0.         0.         0.\n",
      "  0.00598802 0.         0.00598802 0.00299401 0.00898204 0.\n",
      "  0.01796407 0.         0.         0.         0.         0.\n",
      "  0.01197605 0.00299401 0.00299401 0.00299401 0.00299401 0.\n",
      "  0.00898204 0.         0.01197605 0.         0.00598802 0.\n",
      "  0.         0.         0.00598802 0.00299401 0.         0.00598802\n",
      "  0.00598802 0.         0.00299401 0.         0.         0.\n",
      "  0.         0.00299401 0.         0.         0.         0.\n",
      "  0.         0.00299401 0.         0.         0.00598802 0.\n",
      "  0.         0.         0.01796407 0.00598802 0.         0.\n",
      "  0.00299401 0.         0.00299401 0.         0.00299401 0.\n",
      "  0.00299401 0.00299401 0.00598802 0.         0.         0.01197605\n",
      "  0.00598802 0.         0.         0.         0.00598802 0.\n",
      "  0.01796407 0.         0.01497006 0.         0.00299401 0.00898204\n",
      "  0.00598802 0.0239521  0.01197605 0.         0.         0.01497006\n",
      "  0.02994012 0.         0.00299401 0.00299401 0.         0.\n",
      "  0.00299401 0.         0.00598802 0.         0.01497006 0.\n",
      "  0.         0.         0.         0.00299401 0.         0.\n",
      "  0.         0.00299401 0.         0.         0.         0.\n",
      "  0.01197605 0.01197605 0.00299401 0.00898204 0.         0.\n",
      "  0.00898204 0.00598802 0.00299401 0.00299401 0.00598802 0.\n",
      "  0.         0.00898204 0.01197605 0.00898204 0.00598802 0.00299401\n",
      "  0.03293413 0.00299401 0.03293413 0.         0.00299401 0.\n",
      "  0.         0.         0.00598802 0.         0.00898204 0.00598802\n",
      "  0.00299401 0.         0.00299401 0.00299401 0.         0.00299401\n",
      "  0.00299401 0.         0.00299401 0.         0.         0.00598802\n",
      "  0.00299401 0.01796407 0.         0.         0.         0.\n",
      "  0.00299401 0.         0.         0.00898204 0.         0.\n",
      "  0.         0.00299401 0.00898204 0.         0.         0.\n",
      "  0.         0.         0.00299401 0.00299401 0.         0.\n",
      "  0.         0.         0.00898204 0.         0.         0.\n",
      "  0.         0.00598802 0.         0.         0.         0.\n",
      "  0.         0.         0.01796407 0.         0.00299401 0.00299401\n",
      "  0.         0.         0.         0.00598802 0.00898204 0.00598802\n",
      "  0.         0.00598802 0.         0.         0.00898204 0.00299401\n",
      "  0.         0.0239521  0.         0.         0.         0.01497006\n",
      "  0.00898204 0.         0.00598802 0.00299401 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00898204 0.         0.00299401 0.00299401 0.         0.\n",
      "  0.00898204 0.         0.00299401 0.00299401 0.         0.00299401\n",
      "  0.         0.00898204 0.00598802 0.00299401 0.         0.01497006\n",
      "  0.00598802 0.         0.         0.         0.0239521  0.\n",
      "  0.00299401 0.         0.         0.00299401 0.         0.00898204\n",
      "  0.01197605 0.00299401 0.         0.         0.         0.\n",
      "  0.00299401 0.00299401 0.         0.00598802 0.         0.00299401\n",
      "  0.00299401 0.         0.00898204 0.         0.00598802 0.00598802\n",
      "  0.         0.01497006 0.         0.         0.         0.00598802\n",
      "  0.         0.         0.         0.00299401 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread(os.path.join(DATA_DIR, 'Abra', '0282b2f3a22745f1a436054ea15a0ae5.jpg'))\n",
    "cv2.imshow('Exemplo de imagem', im)\n",
    "print('Pressione qualquer tecla para continuar.')\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "a = representa(vocab, im)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "- Modelo Bag of Visual Words produzido por Fábio Ayres.\n",
    "- Dataset: [Pokémon Gen One](https://www.kaggle.com/thedagger/pokemon-generation-one/data) da plataforma Kaggle.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
