{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de \"Bag of Visual Words\"\n",
    "\n",
    "Vocês estão recebendo este código do professor e devem dar o crédito devido, para que não se caracterize a situação de tentar passar esforço dos outros como sendo seu (a.k.a. plágio). Divirtam-se!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\crazy\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\opencv_contrib_python-4.1.1.26-py3.7-win-amd64.egg (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\crazy\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "DATA_DIR = 'data_resized'\n",
    "CATEGORY_LIST = ['Pikachu', 'Mewtwo', 'Charmander', 'Bulbasaur', 'Squirtle']\n",
    "NUM_IMAGES_TRAIN_PER_CATEGORY = 50\n",
    "NUM_IMAGES_TEST_PER_CATEGORY = 15\n",
    "NUM_CLUSTERS = 90\n",
    "YTRAIN = []\n",
    "YTEST = []\n",
    "\n",
    "def get_images_from_category(category, num_train, num_test, data_dir):\n",
    "    category_dir = os.path.join(DATA_DIR, category)\n",
    "    num_total = num_train + num_test\n",
    "    filenames_train = []\n",
    "    filenames_test = []\n",
    "    global YTRAIN \n",
    "    global YTEST \n",
    "    \n",
    "    for k, filename in enumerate(os.listdir(category_dir)):\n",
    "        if k < num_train:\n",
    "            filenames_train.append(os.path.join(category_dir, filename))\n",
    "            YTRAIN.append(category)\n",
    "            print(os.path.join(category_dir, filename))\n",
    "        elif k < num_total:\n",
    "            filenames_test.append(os.path.join(category_dir, filename))\n",
    "            YTEST.append(category)\n",
    "        else:\n",
    "            break\n",
    "    return filenames_train, filenames_test\n",
    "\n",
    "def get_images_from_category_list(category_list, num_train, num_test, data_dir):\n",
    "    filenames_train_all = []\n",
    "    filenames_test_all = []\n",
    "    for category in category_list:\n",
    "        filenames_train, filenames_test = get_images_from_category(category, num_train, num_test, data_dir)\n",
    "        filenames_train_all.extend(filenames_train)\n",
    "        filenames_test_all.extend(filenames_test)\n",
    "    return filenames_train_all, filenames_test_all\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(representa(vocab, img).flatten())\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_resized\\Pikachu\\6975.png\n",
      "data_resized\\Pikachu\\6976.png\n",
      "data_resized\\Pikachu\\6977.png\n",
      "data_resized\\Pikachu\\6978.png\n",
      "data_resized\\Pikachu\\6979.png\n",
      "data_resized\\Pikachu\\6980.png\n",
      "data_resized\\Pikachu\\6981.png\n",
      "data_resized\\Pikachu\\6982.png\n",
      "data_resized\\Pikachu\\6983.png\n",
      "data_resized\\Pikachu\\6984.png\n",
      "data_resized\\Pikachu\\6985.png\n",
      "data_resized\\Pikachu\\6986.png\n",
      "data_resized\\Pikachu\\6987.png\n",
      "data_resized\\Pikachu\\6988.png\n",
      "data_resized\\Pikachu\\6989.png\n",
      "data_resized\\Pikachu\\6990.png\n",
      "data_resized\\Pikachu\\6991.png\n",
      "data_resized\\Pikachu\\6992.png\n",
      "data_resized\\Pikachu\\6993.png\n",
      "data_resized\\Pikachu\\6994.png\n",
      "data_resized\\Pikachu\\6995.png\n",
      "data_resized\\Pikachu\\6996.png\n",
      "data_resized\\Pikachu\\6997.png\n",
      "data_resized\\Pikachu\\6998.png\n",
      "data_resized\\Pikachu\\6999.png\n",
      "data_resized\\Pikachu\\7000.png\n",
      "data_resized\\Pikachu\\7001.png\n",
      "data_resized\\Pikachu\\7002.png\n",
      "data_resized\\Pikachu\\7003.png\n",
      "data_resized\\Pikachu\\7004.png\n",
      "data_resized\\Pikachu\\7005.png\n",
      "data_resized\\Pikachu\\7006.png\n",
      "data_resized\\Pikachu\\7007.png\n",
      "data_resized\\Pikachu\\7008.png\n",
      "data_resized\\Pikachu\\7009.png\n",
      "data_resized\\Pikachu\\7010.png\n",
      "data_resized\\Pikachu\\7011.png\n",
      "data_resized\\Pikachu\\7012.png\n",
      "data_resized\\Pikachu\\7013.png\n",
      "data_resized\\Pikachu\\7014.png\n",
      "data_resized\\Pikachu\\7015.png\n",
      "data_resized\\Pikachu\\7016.png\n",
      "data_resized\\Pikachu\\7017.png\n",
      "data_resized\\Pikachu\\7018.png\n",
      "data_resized\\Pikachu\\7019.png\n",
      "data_resized\\Pikachu\\7020.png\n",
      "data_resized\\Pikachu\\7021.png\n",
      "data_resized\\Pikachu\\7022.png\n",
      "data_resized\\Pikachu\\7023.png\n",
      "data_resized\\Pikachu\\7024.png\n",
      "data_resized\\Mewtwo\\5541.png\n",
      "data_resized\\Mewtwo\\5542.png\n",
      "data_resized\\Mewtwo\\5543.png\n",
      "data_resized\\Mewtwo\\5544.png\n",
      "data_resized\\Mewtwo\\5545.png\n",
      "data_resized\\Mewtwo\\5546.png\n",
      "data_resized\\Mewtwo\\5547.png\n",
      "data_resized\\Mewtwo\\5548.png\n",
      "data_resized\\Mewtwo\\5549.png\n",
      "data_resized\\Mewtwo\\5550.png\n",
      "data_resized\\Mewtwo\\5551.png\n",
      "data_resized\\Mewtwo\\5552.png\n",
      "data_resized\\Mewtwo\\5553.png\n",
      "data_resized\\Mewtwo\\5554.png\n",
      "data_resized\\Mewtwo\\5555.png\n",
      "data_resized\\Mewtwo\\5556.png\n",
      "data_resized\\Mewtwo\\5557.png\n",
      "data_resized\\Mewtwo\\5558.png\n",
      "data_resized\\Mewtwo\\5559.png\n",
      "data_resized\\Mewtwo\\5560.png\n",
      "data_resized\\Mewtwo\\5561.png\n",
      "data_resized\\Mewtwo\\5562.png\n",
      "data_resized\\Mewtwo\\5563.png\n",
      "data_resized\\Mewtwo\\5564.png\n",
      "data_resized\\Mewtwo\\5565.png\n",
      "data_resized\\Mewtwo\\5566.png\n",
      "data_resized\\Mewtwo\\5567.png\n",
      "data_resized\\Mewtwo\\5568.png\n",
      "data_resized\\Mewtwo\\5569.png\n",
      "data_resized\\Mewtwo\\5570.png\n",
      "data_resized\\Mewtwo\\5571.png\n",
      "data_resized\\Mewtwo\\5572.png\n",
      "data_resized\\Mewtwo\\5573.png\n",
      "data_resized\\Mewtwo\\5574.png\n",
      "data_resized\\Mewtwo\\5575.png\n",
      "data_resized\\Mewtwo\\5576.png\n",
      "data_resized\\Mewtwo\\5577.png\n",
      "data_resized\\Mewtwo\\5578.png\n",
      "data_resized\\Mewtwo\\5579.png\n",
      "data_resized\\Mewtwo\\5580.png\n",
      "data_resized\\Mewtwo\\5581.png\n",
      "data_resized\\Mewtwo\\5582.png\n",
      "data_resized\\Mewtwo\\5583.png\n",
      "data_resized\\Mewtwo\\5584.png\n",
      "data_resized\\Mewtwo\\5585.png\n",
      "data_resized\\Mewtwo\\5586.png\n",
      "data_resized\\Mewtwo\\5587.png\n",
      "data_resized\\Mewtwo\\5588.png\n",
      "data_resized\\Mewtwo\\5589.png\n",
      "data_resized\\Mewtwo\\5590.png\n",
      "data_resized\\Charmander\\1053.png\n",
      "data_resized\\Charmander\\1054.png\n",
      "data_resized\\Charmander\\1055.png\n",
      "data_resized\\Charmander\\1056.png\n",
      "data_resized\\Charmander\\1057.png\n",
      "data_resized\\Charmander\\1058.png\n",
      "data_resized\\Charmander\\1059.png\n",
      "data_resized\\Charmander\\1060.png\n",
      "data_resized\\Charmander\\1061.png\n",
      "data_resized\\Charmander\\1062.png\n",
      "data_resized\\Charmander\\1063.png\n",
      "data_resized\\Charmander\\1064.png\n",
      "data_resized\\Charmander\\1065.png\n",
      "data_resized\\Charmander\\1066.png\n",
      "data_resized\\Charmander\\1067.png\n",
      "data_resized\\Charmander\\1068.png\n",
      "data_resized\\Charmander\\1069.png\n",
      "data_resized\\Charmander\\1070.png\n",
      "data_resized\\Charmander\\1071.png\n",
      "data_resized\\Charmander\\1072.png\n",
      "data_resized\\Charmander\\1073.png\n",
      "data_resized\\Charmander\\1074.png\n",
      "data_resized\\Charmander\\1075.png\n",
      "data_resized\\Charmander\\1076.png\n",
      "data_resized\\Charmander\\1077.png\n",
      "data_resized\\Charmander\\1078.png\n",
      "data_resized\\Charmander\\1079.png\n",
      "data_resized\\Charmander\\1080.png\n",
      "data_resized\\Charmander\\1081.png\n",
      "data_resized\\Charmander\\1082.png\n",
      "data_resized\\Charmander\\1083.png\n",
      "data_resized\\Charmander\\1084.png\n",
      "data_resized\\Charmander\\1085.png\n",
      "data_resized\\Charmander\\1086.png\n",
      "data_resized\\Charmander\\1087.png\n",
      "data_resized\\Charmander\\1088.png\n",
      "data_resized\\Charmander\\1089.png\n",
      "data_resized\\Charmander\\1090.png\n",
      "data_resized\\Charmander\\1091.png\n",
      "data_resized\\Charmander\\1092.png\n",
      "data_resized\\Charmander\\1093.png\n",
      "data_resized\\Charmander\\1094.png\n",
      "data_resized\\Charmander\\1095.png\n",
      "data_resized\\Charmander\\1096.png\n",
      "data_resized\\Charmander\\1097.png\n",
      "data_resized\\Charmander\\1098.png\n",
      "data_resized\\Charmander\\1099.png\n",
      "data_resized\\Charmander\\1100.png\n",
      "data_resized\\Charmander\\1101.png\n",
      "data_resized\\Charmander\\1102.png\n",
      "data_resized\\Bulbasaur\\539.png\n",
      "data_resized\\Bulbasaur\\540.png\n",
      "data_resized\\Bulbasaur\\541.png\n",
      "data_resized\\Bulbasaur\\542.png\n",
      "data_resized\\Bulbasaur\\543.png\n",
      "data_resized\\Bulbasaur\\544.png\n",
      "data_resized\\Bulbasaur\\545.png\n",
      "data_resized\\Bulbasaur\\546.png\n",
      "data_resized\\Bulbasaur\\547.png\n",
      "data_resized\\Bulbasaur\\548.png\n",
      "data_resized\\Bulbasaur\\549.png\n",
      "data_resized\\Bulbasaur\\550.png\n",
      "data_resized\\Bulbasaur\\551.png\n",
      "data_resized\\Bulbasaur\\552.png\n",
      "data_resized\\Bulbasaur\\553.png\n",
      "data_resized\\Bulbasaur\\554.png\n",
      "data_resized\\Bulbasaur\\555.png\n",
      "data_resized\\Bulbasaur\\556.png\n",
      "data_resized\\Bulbasaur\\557.png\n",
      "data_resized\\Bulbasaur\\558.png\n",
      "data_resized\\Bulbasaur\\559.png\n",
      "data_resized\\Bulbasaur\\560.png\n",
      "data_resized\\Bulbasaur\\561.png\n",
      "data_resized\\Bulbasaur\\562.png\n",
      "data_resized\\Bulbasaur\\563.png\n",
      "data_resized\\Bulbasaur\\564.png\n",
      "data_resized\\Bulbasaur\\565.png\n",
      "data_resized\\Bulbasaur\\566.png\n",
      "data_resized\\Bulbasaur\\567.png\n",
      "data_resized\\Bulbasaur\\568.png\n",
      "data_resized\\Bulbasaur\\569.png\n",
      "data_resized\\Bulbasaur\\570.png\n",
      "data_resized\\Bulbasaur\\571.png\n",
      "data_resized\\Bulbasaur\\572.png\n",
      "data_resized\\Bulbasaur\\573.png\n",
      "data_resized\\Bulbasaur\\574.png\n",
      "data_resized\\Bulbasaur\\575.png\n",
      "data_resized\\Bulbasaur\\576.png\n",
      "data_resized\\Bulbasaur\\577.png\n",
      "data_resized\\Bulbasaur\\578.png\n",
      "data_resized\\Bulbasaur\\579.png\n",
      "data_resized\\Bulbasaur\\580.png\n",
      "data_resized\\Bulbasaur\\581.png\n",
      "data_resized\\Bulbasaur\\582.png\n",
      "data_resized\\Bulbasaur\\583.png\n",
      "data_resized\\Bulbasaur\\584.png\n",
      "data_resized\\Bulbasaur\\585.png\n",
      "data_resized\\Bulbasaur\\586.png\n",
      "data_resized\\Bulbasaur\\587.png\n",
      "data_resized\\Bulbasaur\\588.png\n",
      "data_resized\\Squirtle\\9079.png\n",
      "data_resized\\Squirtle\\9080.png\n",
      "data_resized\\Squirtle\\9081.png\n",
      "data_resized\\Squirtle\\9082.png\n",
      "data_resized\\Squirtle\\9083.png\n",
      "data_resized\\Squirtle\\9084.png\n",
      "data_resized\\Squirtle\\9085.png\n",
      "data_resized\\Squirtle\\9086.png\n",
      "data_resized\\Squirtle\\9087.png\n",
      "data_resized\\Squirtle\\9088.png\n",
      "data_resized\\Squirtle\\9089.png\n",
      "data_resized\\Squirtle\\9090.png\n",
      "data_resized\\Squirtle\\9091.png\n",
      "data_resized\\Squirtle\\9092.png\n",
      "data_resized\\Squirtle\\9093.png\n",
      "data_resized\\Squirtle\\9094.png\n",
      "data_resized\\Squirtle\\9095.png\n",
      "data_resized\\Squirtle\\9096.png\n",
      "data_resized\\Squirtle\\9097.png\n",
      "data_resized\\Squirtle\\9098.png\n",
      "data_resized\\Squirtle\\9099.png\n",
      "data_resized\\Squirtle\\9100.png\n",
      "data_resized\\Squirtle\\9101.png\n",
      "data_resized\\Squirtle\\9102.png\n",
      "data_resized\\Squirtle\\9103.png\n",
      "data_resized\\Squirtle\\9104.png\n",
      "data_resized\\Squirtle\\9105.png\n",
      "data_resized\\Squirtle\\9106.png\n",
      "data_resized\\Squirtle\\9107.png\n",
      "data_resized\\Squirtle\\9108.png\n",
      "data_resized\\Squirtle\\9109.png\n",
      "data_resized\\Squirtle\\9110.png\n",
      "data_resized\\Squirtle\\9111.png\n",
      "data_resized\\Squirtle\\9112.png\n",
      "data_resized\\Squirtle\\9113.png\n",
      "data_resized\\Squirtle\\9114.png\n",
      "data_resized\\Squirtle\\9115.png\n",
      "data_resized\\Squirtle\\9116.png\n",
      "data_resized\\Squirtle\\9117.png\n",
      "data_resized\\Squirtle\\9118.png\n",
      "data_resized\\Squirtle\\9119.png\n",
      "data_resized\\Squirtle\\9120.png\n",
      "data_resized\\Squirtle\\9121.png\n",
      "data_resized\\Squirtle\\9122.png\n",
      "data_resized\\Squirtle\\9123.png\n",
      "data_resized\\Squirtle\\9124.png\n",
      "data_resized\\Squirtle\\9125.png\n",
      "data_resized\\Squirtle\\9126.png\n",
      "data_resized\\Squirtle\\9127.png\n",
      "data_resized\\Squirtle\\9128.png\n"
     ]
    }
   ],
   "source": [
    "imagens_train, imagens_test = get_images_from_category_list(CATEGORY_LIST, \n",
    "                                                            NUM_IMAGES_TRAIN_PER_CATEGORY, \n",
    "                                                            NUM_IMAGES_TEST_PER_CATEGORY, \n",
    "                                                            DATA_DIR)\n",
    "vocab = cria_vocabulario(imagens_train, NUM_CLUSTERS)\n",
    "X_train = transforma_imagens(imagens_train, vocab)\n",
    "X_test = transforma_imagens(imagens_test, vocab)\n",
    "y_train = np.hstack([np.ones(NUM_IMAGES_TRAIN_PER_CATEGORY), -np.ones(NUM_IMAGES_TRAIN_PER_CATEGORY)])\n",
    "y_test = np.hstack([np.ones(NUM_IMAGES_TEST_PER_CATEGORY), -np.ones(NUM_IMAGES_TEST_PER_CATEGORY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=0, n_estimators = 500)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X_train, YTRAIN)\n",
    "clf.score(X_test, YTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "- Modelo Bag of Visual Words produzido por Fábio Ayres.\n",
    "- Dataset: [Pokémon Gen One](https://www.kaggle.com/thedagger/pokemon-generation-one/data) da plataforma Kaggle.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.fromstring(palavra, dtype = int)\n",
    "\n",
    "palavra = str(X_train.tolist())\n",
    "\n",
    "with open ('image_text.txt', 'w') as image:\n",
    "    conteudo = image.write(palavra)\n",
    "    \n",
    "with open('image_text.txt' , 'r') as image:\n",
    "    content = image.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR2 = 'Testes'\n",
    "CATEGORY_LIST2 = 'Testes'\n",
    "NUM_IMAGES_TRAIN_PER_CATEGORY2 = 5\n",
    "NUM_CLUSTERS2 = 9\n",
    "YTRAIN2 = []\n",
    "\n",
    "\n",
    "def get_images_from_category(category, num_train, data_dir):\n",
    "    category_dir = os.path.join(DATA_DIR2, CATEGORY_LIST2)\n",
    "    num_total = num_train\n",
    "    filenames_train2 = []\n",
    "    global YTRAIN2\n",
    "    \n",
    "    for k, filename in enumerate(os.listdir(category_dir)):\n",
    "        if k <= num_train:\n",
    "            filenames_train2.append(os.path.join(category_dir, filename))\n",
    "            YTRAIN2.append(category)\n",
    "        else:\n",
    "            break\n",
    "    return filenames_train2\n",
    "\n",
    "def get_images_from_category_list2(category_list, num_train, data_dir):\n",
    "    filenames_train_all2 = []\n",
    "    for category in category_list:\n",
    "        filenames_train = get_images_from_category(category, num_train, data_dir)\n",
    "        filenames_train_all2.extend(filenames_train)\n",
    "    return filenames_train_all2\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X2 = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X2.append(representa(vocab, img).flatten())\n",
    "    return np.array(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_train2  = get_images_from_category_list2(CATEGORY_LIST2, NUM_IMAGES_TRAIN_PER_CATEGORY2, DATA_DIR2)\n",
    "X_train2 = transforma_imagens(imagens_train2, vocab)\n",
    "clf.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
