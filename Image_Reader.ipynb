{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de \"Bag of Visual Words\"\n",
    "\n",
    "Vocês estão recebendo este código do professor e devem dar o crédito devido, para que não se caracterize a situação de tentar passar esforço dos outros como sendo seu (a.k.a. plágio). Divirtam-se!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = 'data//pkmn'\n",
    "CATEGORY_LIST = ['dalmatian', 'Faces_easy']\n",
    "NUM_IMAGES_TRAIN_PER_CATEGORY = 30\n",
    "NUM_IMAGES_TEST_PER_CATEGORY = 15\n",
    "NUM_CLUSTERS = 300\n",
    "\n",
    "def get_images_from_category(category, num_train, num_test, data_dir):\n",
    "    category_dir = os.path.join(DATA_DIR, category)\n",
    "    num_total = num_train + num_test\n",
    "    filenames_train = []\n",
    "    filenames_test = []\n",
    "    for k, filename in enumerate(os.listdir(category_dir)):\n",
    "        if k < num_train:\n",
    "            filenames_train.append(os.path.join(category_dir, filename))\n",
    "        elif k < num_total:\n",
    "            filenames_test.append(os.path.join(category_dir, filename))\n",
    "        else:\n",
    "            break\n",
    "    return filenames_train, filenames_test\n",
    "\n",
    "def get_images_from_category_list(category_list, num_train, num_test, data_dir):\n",
    "    filenames_train_all = []\n",
    "    filenames_test_all = []\n",
    "    for category in category_list:\n",
    "        filenames_train, filenames_test = get_images_from_category(category, num_train, num_test, data_dir)\n",
    "        filenames_train_all.extend(filenames_train)\n",
    "        filenames_test_all.extend(filenames_test)\n",
    "    return filenames_train_all, filenames_test_all\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(representa(vocab, img).flatten())\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_train, imagens_test = get_images_from_category_list(CATEGORY_LIST, \n",
    "                                                            NUM_IMAGES_TRAIN_PER_CATEGORY, \n",
    "                                                            NUM_IMAGES_TEST_PER_CATEGORY, \n",
    "                                                            DATA_DIR)\n",
    "vocab = cria_vocabulario(imagens_train, NUM_CLUSTERS)\n",
    "X_train = transforma_imagens(imagens_train, vocab)\n",
    "X_test = transforma_imagens(imagens_test, vocab)\n",
    "y_train = np.hstack([np.ones(NUM_IMAGES_TRAIN_PER_CATEGORY), -np.ones(NUM_IMAGES_TRAIN_PER_CATEGORY)])\n",
    "y_test = np.hstack([np.ones(NUM_IMAGES_TEST_PER_CATEGORY), -np.ones(NUM_IMAGES_TEST_PER_CATEGORY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 300)\n",
      "(30, 300)\n",
      "(60,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressione qualquer tecla para continuar.\n",
      "[[0.00364299 0.00910747 0.00364299 0.01092896 0.01092896 0.\n",
      "  0.         0.         0.00728597 0.         0.00364299 0.\n",
      "  0.00364299 0.         0.00546448 0.00546448 0.00546448 0.00364299\n",
      "  0.00182149 0.00182149 0.         0.         0.00364299 0.00364299\n",
      "  0.00182149 0.00546448 0.00182149 0.00364299 0.         0.\n",
      "  0.00364299 0.00182149 0.         0.00910747 0.         0.00364299\n",
      "  0.00182149 0.00546448 0.         0.00182149 0.01275046 0.00182149\n",
      "  0.         0.         0.         0.         0.00728597 0.00182149\n",
      "  0.00546448 0.00364299 0.         0.00728597 0.         0.00182149\n",
      "  0.00728597 0.00546448 0.00546448 0.01639344 0.         0.\n",
      "  0.00728597 0.         0.02003643 0.         0.         0.00728597\n",
      "  0.00182149 0.         0.00546448 0.00364299 0.00182149 0.\n",
      "  0.00182149 0.00182149 0.00364299 0.         0.00728597 0.\n",
      "  0.         0.         0.00182149 0.00364299 0.00364299 0.00182149\n",
      "  0.00364299 0.00182149 0.         0.00910747 0.         0.00546448\n",
      "  0.00546448 0.         0.00182149 0.00546448 0.         0.00546448\n",
      "  0.         0.02367942 0.00728597 0.         0.00546448 0.00182149\n",
      "  0.         0.         0.00910747 0.00182149 0.00546448 0.01275046\n",
      "  0.         0.00182149 0.         0.         0.         0.00728597\n",
      "  0.         0.00910747 0.00910747 0.         0.         0.01092896\n",
      "  0.00364299 0.00364299 0.         0.         0.00364299 0.\n",
      "  0.00546448 0.00182149 0.         0.00182149 0.00728597 0.00364299\n",
      "  0.00546448 0.         0.01092896 0.         0.00182149 0.\n",
      "  0.00364299 0.00182149 0.00728597 0.         0.00546448 0.00364299\n",
      "  0.         0.         0.00182149 0.00182149 0.00364299 0.00182149\n",
      "  0.00364299 0.         0.00182149 0.         0.00182149 0.00182149\n",
      "  0.00364299 0.00546448 0.00546448 0.         0.00364299 0.\n",
      "  0.00364299 0.         0.00546448 0.         0.00364299 0.00182149\n",
      "  0.         0.00364299 0.00364299 0.         0.00728597 0.00364299\n",
      "  0.         0.00546448 0.         0.00182149 0.00364299 0.00182149\n",
      "  0.         0.00364299 0.00182149 0.00728597 0.         0.00364299\n",
      "  0.00728597 0.         0.         0.         0.00364299 0.\n",
      "  0.         0.         0.00182149 0.         0.         0.\n",
      "  0.         0.00728597 0.00546448 0.00364299 0.00182149 0.00182149\n",
      "  0.         0.00546448 0.         0.01821494 0.00728597 0.00182149\n",
      "  0.00546448 0.01639344 0.00182149 0.01092896 0.00546448 0.00728597\n",
      "  0.00364299 0.00546448 0.01092896 0.00182149 0.         0.00546448\n",
      "  0.00182149 0.01092896 0.00546448 0.01275046 0.00182149 0.\n",
      "  0.00182149 0.         0.00728597 0.         0.00182149 0.00364299\n",
      "  0.00546448 0.         0.00546448 0.         0.         0.00546448\n",
      "  0.00182149 0.00364299 0.00364299 0.         0.00182149 0.00364299\n",
      "  0.00182149 0.         0.         0.00546448 0.         0.00182149\n",
      "  0.         0.         0.03642987 0.         0.00546448 0.00364299\n",
      "  0.         0.00546448 0.00182149 0.         0.00364299 0.00546448\n",
      "  0.00728597 0.00182149 0.01092896 0.         0.         0.00546448\n",
      "  0.00182149 0.         0.00546448 0.00364299 0.         0.\n",
      "  0.00182149 0.         0.00182149 0.         0.         0.00182149\n",
      "  0.01092896 0.00182149 0.00182149 0.00546448 0.         0.\n",
      "  0.00728597 0.         0.00182149 0.00182149 0.00910747 0.00910747\n",
      "  0.00546448 0.00182149 0.00546448 0.00182149 0.00910747 0.00910747]]\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread(os.path.join(DATA_DIR, 'dalmatian', 'image_0021.jpg'))\n",
    "cv2.imshow('Exemplo de imagem', im)\n",
    "print('Pressione qualquer tecla para continuar.')\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "a = representa(vocab, im)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "- Modelo Bag of Visual Words produzido por Fábio Ayres.\n",
    "- Dataset: [Pokémon Gen One](https://www.kaggle.com/thedagger/pokemon-generation-one/data) da plataforma Kaggle.com\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
