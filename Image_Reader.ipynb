{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de \"Bag of Visual Words\"\n",
    "\n",
    "Vocês estão recebendo este código do professor e devem dar o crédito devido, para que não se caracterize a situação de tentar passar esforço dos outros como sendo seu (a.k.a. plágio). Divirtam-se!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\crazy\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\opencv_contrib_python-4.1.1.26-py3.7-win-amd64.egg (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\crazy\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "DATA_DIR = 'data_resized'\n",
    "CATEGORY_LIST = ['Mewtwo', 'Pikachu', 'Squirtle']\n",
    "NUM_IMAGES_TRAIN_PER_CATEGORY = 80\n",
    "NUM_IMAGES_TEST_PER_CATEGORY = 20\n",
    "NUM_CLUSTERS = 50\n",
    "\n",
    "def get_images_from_category(category, num_train, num_test, data_dir):\n",
    "    category_dir = os.path.join(DATA_DIR, category)\n",
    "    num_total = num_train + num_test\n",
    "    filenames_train = []\n",
    "    filenames_test = []\n",
    "    \n",
    "    for k, filename in enumerate(os.listdir(category_dir)):\n",
    "        if k < num_train:\n",
    "            filenames_train.append(os.path.join(category_dir, filename))\n",
    "        elif k < num_total:\n",
    "            filenames_test.append(os.path.join(category_dir, filename))\n",
    "        else:\n",
    "            break\n",
    "    return filenames_train, filenames_test\n",
    "\n",
    "def get_images_from_category_list(category_list, num_train, num_test, data_dir):\n",
    "    filenames_train_all = []\n",
    "    target_train = []\n",
    "    filenames_test_all = []\n",
    "    target_test = []\n",
    "    for category in category_list:\n",
    "        filenames_train, filenames_test = get_images_from_category(category, num_train, num_test, data_dir)\n",
    "        filenames_train_all.extend(filenames_train)\n",
    "        target_train.extend([category] * NUM_IMAGES_TRAIN_PER_CATEGORY)\n",
    "        filenames_test_all.extend(filenames_test)\n",
    "        target_test.extend([category] * NUM_IMAGES_TEST_PER_CATEGORY)\n",
    "    return filenames_train_all, filenames_test_all, target_train, target_test\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(representa(vocab, img).flatten())\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_train, imagens_test, target_train, target_test = get_images_from_category_list(CATEGORY_LIST, \n",
    "                                                                                        NUM_IMAGES_TRAIN_PER_CATEGORY, \n",
    "                                                                                        NUM_IMAGES_TEST_PER_CATEGORY, \n",
    "                                                                                        DATA_DIR)\n",
    "vocab = cria_vocabulario(imagens_train, NUM_CLUSTERS)\n",
    "X_train = transforma_imagens(imagens_train, vocab)\n",
    "X_test = transforma_imagens(imagens_test, vocab)\n",
    "y_train = target_train\n",
    "y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crazy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\crazy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "- Modelo Bag of Visual Words produzido por Fábio Ayres.\n",
    "- Dataset: [Pokémon Gen One](https://www.kaggle.com/thedagger/pokemon-generation-one/data) da plataforma Kaggle.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.fromstring(palavra, dtype = int)\n",
    "\n",
    "palavra = str(X_train.tolist())\n",
    "\n",
    "with open ('image_text.txt', 'w') as image:\n",
    "    conteudo = image.write(palavra)\n",
    "    \n",
    "with open('image_text.txt' , 'r') as image:\n",
    "    content = image.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30308209, 0.33852438, 0.35839352]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"Testes/Testes/squirtle.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img_resized = cv2.resize(img, dsize=(120, 120), interpolation=cv2.INTER_CUBIC)\n",
    "# plt.imshow(img_resized, cmap='gray', vmin=0, vmax=255)\n",
    "features_img = representa(vocab, img_resized)\n",
    "clf.predict_proba(features_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_predict_proba_lr',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'dual',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'intercept_scaling',\n",
       " 'max_iter',\n",
       " 'multi_class',\n",
       " 'n_iter_',\n",
       " 'n_jobs',\n",
       " 'penalty',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'solver',\n",
       " 'sparsify',\n",
       " 'tol',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
