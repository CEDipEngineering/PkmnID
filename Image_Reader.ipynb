{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final de Ciência dos Dados. ( PkmnID)\n",
    "\n",
    "## Algoritmo de predição da categoria de Pokémons por meio de suas imagens.\n",
    "### O algoritmo realiza a extração e a clusterização de features de imagens por meio do método \\\"Bag of Visual Words\\\" (BOVW),classifica-as utilizando o método de machine learning \\\"Random Forest\\\" e prevê a categoria de Pokémons por meio de novas imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.1.26)\nRequirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.15.4)\n"
    }
   ],
   "source": [
    "!pip install opencv-contrib-python\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "TRAIN_DIR = 'Assets//Data_Train'\n",
    "TEST_DIR = 'Assets//Data_Test'\n",
    "\n",
    "NUM_CLUSTERS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Máquina de controle:\n",
    "\n",
    "# Extrai as features de todas as imagens novamente.\n",
    "RE_EXTRACT_FEATURES = 0\n",
    "\n",
    "# Re-extrai os nomes das imagens (com os caminhos adequados), de cada pasta.\n",
    "RE_ACQUIRE_IMG_NAMES = 0\n",
    "\n",
    "# Re-constrói o dicionário de features que permite a análise exploratória.\n",
    "RE_CREATE_FEATURE_DICT = 0\n",
    "\n",
    "# Cria arquivo Json para dicionário de Features.\n",
    "CREATE_JSON = 0\n",
    "\n",
    "# Constrói dataframe com dados do dicionário de features.\n",
    "CREATE_FEATURE_DATAFRAME = 1\n",
    "\n",
    "# Mostra em quais 'n' pokémons, cada feature é mais proeminente.\n",
    "SHOW_TOP_N_FOR_FEATURES = 1\n",
    "\n",
    "# Re-treina os models.\n",
    "FIT_MODELS = 0\n",
    "\n",
    "# Produz matrizes de confusão para todos os modelos.\n",
    "PLOT_CONFUSION_MATRIXES = 0\n",
    "\n",
    "# Produz uma lista com a métrica precision@n para todos os modelos.\n",
    "PRECISION_AT_N = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Extração de features de imagens: Bag of Visual Words\n",
    "### Uma vez que o dataset se trata de um conjunto de imagens de diferentes Pokémons, é necessário inicialmente extrair features dessas imagens, através do método \"Bag of Visual Words\".\n",
    "### Com as imagens transformadas em features clusterizadas, elas são separadas em categorias de treino e teste, que serão utilizadas posteriormente pelo algoritmo de machine learning.\n",
    "### O código abaixo realiza essas duas etapas:\n",
    "#### Obs: Código produzido com a assistência do Prof. Fábio Ayres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_names(TRAIN_DIR = TRAIN_DIR, TEST_DIR = TEST_DIR):\n",
    "\n",
    "    TRAIN_IMG = []\n",
    "    TEST_IMG = []\n",
    "    TRAIN_LABEL = []\n",
    "    TEST_LABEL = []\n",
    "\n",
    "    for train, test in zip(os.listdir(TRAIN_DIR), os.listdir(TEST_DIR)): #Tecnicamente são iguais, mas não custa garantir.\n",
    "        for img_train, img_test in zip(os.listdir(os.path.join(TRAIN_DIR,train)), os.listdir(os.path.join(TEST_DIR,test))):\n",
    "            TRAIN_IMG.append(os.path.join(TRAIN_DIR,train,img_train))\n",
    "            TEST_IMG.append(os.path.join(TEST_DIR,test,img_test))\n",
    "            TRAIN_LABEL.append(train)\n",
    "            TEST_LABEL.append(test)\n",
    "\n",
    "    return TRAIN_IMG, TEST_IMG, TRAIN_LABEL, TEST_LABEL\n",
    "\n",
    "def cria_vocabulario(imagens, num_clusters):\n",
    "    km = cv2.BOWKMeansTrainer(num_clusters)\n",
    "    akaze = cv2.KAZE_create()\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.ones(img.shape)\n",
    "        kp, desc = akaze.detectAndCompute(img, mask)\n",
    "        km.add(desc)\n",
    "    return km.cluster()\n",
    "\n",
    "def representa(vocab, img):\n",
    "    kaze = cv2.KAZE_create()\n",
    "    kp = kaze.detect(img)\n",
    "    bowdesc = cv2.BOWImgDescriptorExtractor(kaze, cv2.FlannBasedMatcher())\n",
    "    bowdesc.setVocabulary(vocab)\n",
    "    return bowdesc.compute(img, kp)\n",
    "\n",
    "def transforma_imagens(imagens, vocab):\n",
    "    X = []\n",
    "    for p in imagens:\n",
    "        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(representa(vocab, img).flatten())\n",
    "    return np.array(X)\n",
    "\n",
    "def show_example(path = os.listdir(\"Testes/Testes/\")[0], Plot = True):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, dsize=(120, 120))\n",
    "    if Plot:\n",
    "        plt.imshow(img_resized, cmap='gray', vmin=0, vmax=255)\n",
    "    return representa(vocab, img_resized)\n",
    "\n",
    "if RE_ACQUIRE_IMG_NAMES:\n",
    "    TRAIN_IMG, TEST_IMG, TRAIN_LABEL, TEST_LABEL = get_img_names()\n",
    "\n",
    "if RE_EXTRACT_FEATURES:\n",
    "    vocab = cria_vocabulario(TRAIN_IMG, NUM_CLUSTERS)\n",
    "    X_train = transforma_imagens(TRAIN_IMG, vocab)\n",
    "    X_test = transforma_imagens(TEST_IMG, vocab)\n",
    "    y_train = TRAIN_LABEL\n",
    "    y_test = TEST_LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Análise Exploratória:\n",
    "### Para realizar a análise exploratória seguiremos alguns passos:\n",
    "### 2.1 - Extrair histograma:\n",
    "### O código abaixo cria o histograma de frequências relativas das features de todas as imagens do dataset escolhido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "3 0.06...\n21     [[0.   0.11 0.   0.02 0.01 0.   0.07 0.03 0.04...\n22     [[0.   0.12 0.   0.02 0.01 0.   0.07 0.03 0.05...\n23     [[0.   0.13 0.   0.02 0.01 0.   0.07 0.03 0.05...\n24     [[0.01 0.04 0.   0.14 0.04 0.06 0.04 0.   0.  ...\n25     [[0.   0.   0.03 0.05 0.05 0.01 0.02 0.01 0.01...\n26     [[0.   0.   0.03 0.05 0.04 0.01 0.02 0.02 0.01...\n27     [[0.   0.   0.02 0.05 0.04 0.01 0.02 0.01 0.01...\n28     [[0.   0.   0.03 0.05 0.03 0.01 0.03 0.02 0.01...\n29     [[0.   0.   0.19 0.01 0.06 0.01 0.01 0.01 0.02...\n                             ...                        \n254    [[0.   0.06 0.   0.06 0.   0.   0.08 0.01 0.03...\n255    [[0.   0.06 0.01 0.05 0.   0.   0.08 0.01 0.05...\n256    [[0.   0.04 0.01 0.07 0.   0.   0.06 0.01 0.08...\n257    [[0.   0.06 0.   0.07 0.   0.   0.09 0.02 0.05...\n258    [[0.   0.   0.07 0.09 0.06 0.01 0.01 0.07 0.  ...\n259    [[0.01 0.   0.06 0.09 0.05 0.   0.02 0.07 0.  ...\n260    [[0.01 0.   0.02 0.08 0.05 0.01 0.02 0.07 0.  ...\n261    [[0.01 0.   0.04 0.08 0.05 0.01 0.01 0.07 0.  ...\n262    [[0.   0.03 0.06 0.06 0.03 0.   0.02 0.05 0.  ...\n263    [[0.   0.09 0.   0.02 0.   0.   0.07 0.   0.06...\n264    [[0.   0.09 0.   0.02 0.   0.   0.07 0.   0.08...\n265    [[0.   0.06 0.   0.02 0.   0.   0.07 0.   0.05...\n266    [[0.   0.07 0.   0.02 0.   0.   0.07 0.   0.07...\n267    [[0.   0.05 0.   0.02 0.   0.02 0.05 0.01 0.03...\n268    [[0.   0.06 0.   0.02 0.   0.02 0.03 0.01 0.03...\n269    [[0.   0.03 0.   0.02 0.   0.02 0.03 0.01 0.03...\n270    [[0.   0.04 0.   0.02 0.   0.02 0.03 0.01 0.04...\n271    [[0.   0.01 0.05 0.01 0.   0.01 0.01 0.01 0.  ...\n272    [[0.05 0.01 0.03 0.03 0.01 0.04 0.01 0.01 0.01...\n273    [[0.01 0.02 0.06 0.05 0.04 0.   0.03 0.05 0.  ...\n274    [[0.06 0.01 0.   0.05 0.01 0.05 0.01 0.06 0.  ...\n275    [[0.03 0.01 0.01 0.03 0.03 0.03 0.03 0.09 0.  ...\n276    [[0.   0.   0.14 0.05 0.07 0.   0.   0.08 0.01...\n277    [[0.   0.   0.12 0.04 0.07 0.02 0.01 0.07 0.01...\n278    [[0.   0.   0.13 0.05 0.07 0.02 0.   0.08 0.01...\n279    [[0.   0.   0.15 0.04 0.07 0.   0.   0.07 0.01...\n280    [[0.   0.   0.1  0.02 0.   0.   0.   0.   0.  ...\n281    [[0.   0.   0.1  0.02 0.   0.01 0.   0.   0.  ...\n282    [[0.   0.   0.1  0.02 0.   0.01 0.   0.   0.  ...\n283    [[0.   0.   0.11 0.02 0.   0.   0.   0.   0.  ...\nName: Charmander, Length: 284, dtype: object,\n 'Jigglypuff': 0      [[0.   0.   0.1  0.01 0.01 0.01 0.   0.04 0.  ...\n1      [[0.   0.03 0.01 0.03 0.   0.01 0.03 0.   0.09...\n2      [[0.   0.03 0.01 0.03 0.   0.01 0.01 0.   0.07...\n3      [[0.   0.03 0.01 0.02 0.   0.01 0.02 0.   0.08...\n4      [[0.   0.01 0.01 0.03 0.   0.01 0.02 0.   0.1 ...\n5      [[0.   0.   0.11 0.   0.02 0.   0.   0.   0.  ...\n6      [[0.   0.   0.11 0.   0.02 0.   0.   0.   0.  ...\n7      [[0.   0.   0.11 0.   0.02 0.   0.   0.   0.  ...\n8      [[0.   0.   0.13 0.   0.02 0.02 0.   0.   0.  ...\n9      [[0.   0.   0.1  0.01 0.02 0.   0.   0.04 0.  ...\n10     [[0.12 0.03 0.   0.   0.   0.   0.02 0.03 0.  ...\n11     [[0.1  0.03 0.   0.   0.   0.02 0.02 0.05 0.  ...\n12     [[0.02 0.03 0.03 0.   0.   0.02 0.02 0.05 0.  ...\n13     [[0.05 0.03 0.02 0.   0.   0.02 0.02 0.02 0.  ...\n14     [[0.   0.04 0.   0.   0.   0.   0.02 0.   0.11...\n15     [[0.   0.06 0.   0.   0.   0.   0.04 0.01 0.1 ...\n16     [[0.   0.06 0.   0.   0.   0.   0.03 0.01 0.16...\n17     [[0.   0.05 0.   0.   0.   0.   0.04 0.01 0.14...\n18     [[0.   0.04 0.   0.01 0.03 0.   0.03 0.01 0.08...\n19     [[0.   0.01 0.   0.01 0.   0.02 0.06 0.02 0.03...\n20     [[0.   0.01 0.01 0.   0.01 0.02 0.02 0.02 0.05...\n21     [[0.   0.01 0.02 0.   0.   0.03 0.03 0.03 0.07...\n22     [[0.   0.01 0.   0.01 0.01 0.02 0.06 0.02 0.02...\n23     [[0.01 0.   0.05 0.03 0.05 0.   0.   0.09 0.  ...\n24     [[0.   0.   0.05 0.03 0.08 0.01 0.   0.05 0.  ...\n25     [[0.   0.04 0.   0.01 0.03 0.   0.03 0.01 0.07...\n26     [[0.   0.   0.05 0.03 0.03 0.04 0.   0.05 0.  ...\n27     [[0.01 0.   0.05 0.03 0.05 0.03 0.   0.08 0.  ...\n28     [[0.   0.03 0.01 0.03 0.   0.01 0.03 0.   0.09...\n29     [[0.   0.03 0.01 0.03 0.   0.01 0.01 0.   0.07...\n                             ...                        \n310    [[0.   0.   0.04 0.04 0.04 0.   0.01 0.03 0.  ...\n311    [[0.03 0.   0.04 0.04 0.05 0.01 0.   0.03 0.  ...\n312    [[0.01 0.06 0.01 0.   0.   0.   0.04 0.   0.05...\n313    [[0.   0.   0.08 0.06 0.04 0.   0.   0.02 0.  ...\n314    [[0.   0.   0.06 0.06 0.04 0.   0.   0.03 0.  ...\n315    [[0.   0.   0.07 0.06 0.04 0.   0.   0.02 0.  ...\n316    [[0.   0.   0.07 0.06 0.04 0.   0.   0.03 0.  ...\n317    [[0.   0.05 0.02 0.   0.01 0.01 0.01 0.01 0.06...\n318    [[0.   0.04 0.02 0.01 0.01 0.02 0.02 0.   0.07...\n319    [[0.01 0.04 0.01 0.   0.   0.   0.02 0.   0.04...\n320    [[0.   0.04 0.02 0.01 0.01 0.01 0.02 0.01 0.06...\n321    [[0.   0.03 0.02 0.   0.01 0.02 0.02 0.   0.07...\n322    [[0.   0.   0.11 0.01 0.02 0.   0.   0.04 0.  ...\n323    [[0.   0.04 0.   0.   0.   0.   0.02 0.   0.11...\n324    [[0.   0.06 0.   0.   0.   0.   0.04 0.01 0.1 ...\n325    [[0.   0.06 0.   0.   0.   0.   0.03 0.01 0.16...\n326    [[0.   0.05 0.   0.   0.   0.   0.04 0.01 0.14...\n327    [[0.   0.1  0.   0.01 0.01 0.   0.04 0.01 0.1 ...\n328    [[0.   0.09 0.01 0.01 0.   0.01 0.03 0.01 0.11...\n329    [[0.01 0.   0.12 0.01 0.01 0.   0.   0.04 0.  ...\n330    [[0.   0.1  0.   0.01 0.   0.01 0.05 0.02 0.1 ...\n331    [[0.   0.09 0.01 0.01 0.   0.   0.03 0.02 0.11...\n332    [[0.   0.01 0.   0.01 0.   0.02 0.06 0.02 0.03...\n333    [[0.   0.01 0.01 0.   0.01 0.02 0.02 0.02 0.05...\n334    [[0.   0.01 0.02 0.   0.   0.03 0.04 0.03 0.06...\n335    [[0.   0.01 0.   0.01 0.01 0.02 0.06 0.02 0.02...\n336    [[0.01 0.   0.05 0.03 0.05 0.   0.   0.09 0.  ...\n337    [[0.   0.   0.05 0.03 0.08 0.01 0.   0.05 0.  ...\n338    [[0.   0.   0.05 0.03 0.03 0.04 0.   0.05 0.  ...\n339    [[0.01 0.   0.05 0.03 0.05 0.03 0.   0.08 0.  ...\nName: Jigglypuff, Length: 340, dtype: object,\n 'Meowth': 0      [[0.   0.03 0.03 0.04 0.06 0.   0.03 0.04 0.04...\n1      [[0.01 0.03 0.02 0.05 0.04 0.05 0.05 0.04 0.05...\n2      [[0.   0.   0.   0.01 0.03 0.   0.04 0.01 0.02...\n3      [[0.   0.01 0.01 0.02 0.01 0.   0.02 0.08 0.07...\n4      [[0.   0.   0.   0.01 0.   0.   0.01 0.05 0.02...\n5      [[0.   0.   0.   0.01 0.   0.   0.01 0.06 0.05...\n6      [[0.   0.02 0.01 0.02 0.01 0.   0.02 0.07 0.03...\n7      [[0.   0.05 0.   0.   0.01 0.   0.05 0.01 0.08...\n8      [[0.   0.   0.   0.   0.01 0.   0.01 0.   0.08...\n9      [[0.   0.   0.   0.   0.01 0.   0.02 0.   0.07...\n10     [[0.   0.05 0.   0.   0.01 0.   0.03 0.   0.08...\n11     [[0.   0.12 0.01 0.   0.   0.   0.08 0.01 0.07...\n12     [[0.   0.04 0.01 0.   0.   0.   0.03 0.02 0.09...\n13     [[0.   0.01 0.   0.03 0.04 0.   0.05 0.03 0.02...\n14     [[0.   0.05 0.01 0.   0.   0.   0.05 0.02 0.07...\n15     [[0.   0.1  0.01 0.   0.   0.   0.07 0.01 0.1 ...\n16     [[0.   0.04 0.   0.   0.01 0.01 0.08 0.01 0.1 ...\n17     [[0.   0.   0.   0.   0.01 0.01 0.03 0.01 0.08...\n18     [[0.   0.   0.   0.   0.01 0.01 0.03 0.01 0.08...\n19     [[0.   0.04 0.   0.   0.01 0.01 0.06 0.01 0.11...\n20     [[0.01 0.   0.05 0.   0.01 0.01 0.   0.02 0.  ...\n21     [[0.03 0.   0.03 0.   0.01 0.03 0.   0.02 0.  ...\n22     [[0.02 0.   0.04 0.   0.   0.03 0.   0.02 0.  ...\n23     [[0.02 0.   0.04 0.   0.02 0.02 0.   0.02 0.  ...\n24     [[0.01 0.   0.03 0.02 0.01 0.01 0.   0.04 0.  ...\n25     [[0.   0.06 0.   0.   0.   0.   0.01 0.01 0.12...\n26     [[0.   0.08 0.   0.   0.   0.   0.01 0.03 0.12...\n27     [[0.   0.06 0.   0.   0.   0.   0.01 0.01 0.12...\n28     [[0.   0.08 0.   0.   0.   0.   0.01 0.03 0.13...\n29     [[0.   0.   0.06 0.01 0.02 0.   0.01 0.04 0.01...\n                             ...                        \n298    [[0.01 0.   0.07 0.   0.06 0.   0.   0.07 0.  ...\n299    [[0.   0.   0.02 0.   0.08 0.   0.   0.07 0.  ...\n300    [[0.   0.   0.04 0.   0.06 0.   0.   0.06 0.  ...\n301    [[0.   0.   0.05 0.   0.08 0.   0.   0.08 0.  ...\n302    [[0.01 0.08 0.01 0.   0.01 0.01 0.05 0.01 0.06...\n303    [[0.   0.03 0.01 0.   0.01 0.   0.05 0.01 0.05...\n304    [[0.   0.06 0.01 0.   0.   0.   0.04 0.01 0.05...\n305    [[0.01 0.08 0.01 0.   0.   0.   0.05 0.02 0.06...\n306    [[0.   0.01 0.   0.03 0.05 0.   0.05 0.03 0.02...\n307    [[0.   0.05 0.   0.   0.01 0.   0.05 0.01 0.08...\n308    [[0.   0.   0.   0.   0.01 0.   0.01 0.   0.08...\n309    [[0.   0.   0.   0.   0.01 0.   0.02 0.   0.07...\n310    [[0.   0.05 0.   0.   0.01 0.   0.03 0.   0.08...\n311    [[0.   0.12 0.01 0.   0.   0.   0.08 0.01 0.07...\n312    [[0.   0.04 0.01 0.   0.   0.   0.03 0.02 0.09...\n313    [[0.   0.05 0.01 0.   0.   0.   0.05 0.02 0.07...\n314    [[0.   0.1  0.01 0.   0.   0.   0.07 0.01 0.1 ...\n315    [[0.   0.04 0.   0.   0.01 0.01 0.08 0.01 0.1 ...\n316    [[0.   0.   0.   0.   0.01 0.01 0.03 0.01 0.08...\n317    [[0.   0.   0.   0.01 0.03 0.   0.03 0.02 0.03...\n318    [[0.   0.   0.   0.   0.01 0.01 0.03 0.01 0.08...\n319    [[0.   0.04 0.   0.   0.01 0.01 0.06 0.01 0.11...\n320    [[0.   0.05 0.   0.   0.   0.   0.06 0.02 0.13...\n321    [[0.   0.03 0.   0.   0.   0.   0.06 0.02 0.13...\n322    [[0.   0.02 0.   0.   0.   0.   0.06 0.02 0.14...\n323    [[0.   0.04 0.   0.   0.   0.   0.06 0.01 0.12...\n324    [[0.01 0.08 0.01 0.   0.01 0.01 0.05 0.01 0.06...\n325    [[0.   0.03 0.01 0.   0.01 0.   0.05 0.01 0.05...\n326    [[0.   0.06 0.01 0.   0.   0.   0.04 0.01 0.05...\n327    [[0.01 0.08 0.01 0.   0.   0.   0.05 0.03 0.06...\nName: Meowth, Length: 328, dtype: object,\n 'Pidgey': 0      [[0.   0.07 0.   0.02 0.   0.   0.03 0.   0.12...\n1      [[0.   0.02 0.   0.02 0.   0.   0.04 0.01 0.1 ...\n2      [[0.   0.   0.13 0.04 0.04 0.   0.   0.03 0.  ...\n3      [[0.   0.   0.07 0.04 0.08 0.01 0.01 0.07 0.  ...\n4      [[0.09 0.   0.05 0.03 0.07 0.08 0.01 0.05 0.  ...\n5      [[0.09 0.   0.05 0.04 0.07 0.05 0.01 0.07 0.  ...\n6      [[0.   0.   0.08 0.03 0.08 0.   0.01 0.08 0.  ...\n7      [[0.02 0.   0.06 0.03 0.05 0.   0.03 0.08 0.  ...\n8      [[0.02 0.   0.04 0.06 0.05 0.   0.03 0.05 0.  ...\n9      [[0.04 0.   0.04 0.05 0.09 0.   0.03 0.05 0.  ...\n10     [[0.03 0.   0.07 0.05 0.06 0.   0.03 0.08 0.  ...\n11     [[0.02 0.   0.02 0.   0.   0.   0.   0.01 0.  ...\n12     [[0.02 0.   0.01 0.   0.   0.   0.   0.04 0.  ...\n13     [[0.   0.   0.13 0.04 0.05 0.   0.   0.02 0.  ...\n14     [[0.   0.   0.02 0.   0.   0.   0.   0.02 0.  ...\n15     [[0.   0.   0.02 0.   0.   0.   0.   0.04 0.  ...\n16     [[0.   0.05 0.02 0.   0.   0.01 0.07 0.   0.07...\n17     [[0.   0.06 0.01 0.   0.   0.01 0.06 0.   0.02...\n18     [[0.   0.03 0.02 0.   0.   0.01 0.07 0.   0.02...\n19     [[0.   0.04 0.01 0.   0.   0.01 0.08 0.   0.09...\n20     [[0.   0.   0.09 0.04 0.02 0.01 0.01 0.03 0.01...\n21     [[0.01 0.   0.09 0.04 0.02 0.   0.01 0.01 0.01...\n22     [[0.01 0.   0.1  0.04 0.03 0.   0.01 0.01 0.01...\n23     [[0.   0.   0.1  0.03 0.04 0.01 0.01 0.03 0.01...\n24     [[0.   0.   0.15 0.07 0.04 0.01 0.01 0.01 0.  ...\n25     [[0.02 0.02 0.01 0.   0.01 0.01 0.02 0.05 0.02...\n26     [[0.   0.01 0.   0.   0.02 0.01 0.   0.04 0.  ...\n27     [[0.02 0.01 0.01 0.   0.02 0.01 0.   0.04 0.  ...\n28     [[0.03 0.02 0.   0.   0.01 0.02 0.01 0.05 0.02...\n29     [[0.   0.   0.14 0.04 0.03 0.01 0.01 0.02 0.  ...\n                             ...                        \n414    [[0.   0.   0.04 0.04 0.05 0.   0.01 0.01 0.01...\n415    [[0.06 0.   0.06 0.04 0.03 0.01 0.01 0.01 0.01...\n416    [[0.07 0.   0.07 0.04 0.04 0.01 0.01 0.01 0.  ...\n417    [[0.   0.   0.04 0.04 0.05 0.   0.01 0.01 0.01...\n418    [[0.   0.03 0.   0.02 0.01 0.   0.06 0.02 0.08...\n419    [[0.   0.01 0.   0.02 0.   0.   0.06 0.02 0.05...\n420    [[0.   0.03 0.   0.02 0.   0.   0.06 0.02 0.08...\n421    [[0.   0.03 0.   0.02 0.   0.   0.06 0.02 0.09...\n422    [[0.   0.   0.12 0.04 0.04 0.   0.   0.03 0.  ...\n423    [[0.   0.01 0.08 0.06 0.09 0.   0.   0.07 0.  ...\n424    [[0.   0.01 0.08 0.06 0.07 0.   0.   0.08 0.  ...\n425    [[0.02 0.01 0.05 0.02 0.06 0.   0.   0.06 0.  ...\n426    [[0.03 0.01 0.05 0.01 0.04 0.   0.   0.07 0.  ...\n427    [[0.   0.16 0.   0.   0.   0.   0.03 0.   0.09...\n428    [[0.   0.15 0.   0.   0.   0.   0.03 0.   0.09...\n429    [[0.   0.14 0.   0.   0.   0.   0.03 0.   0.09...\n430    [[0.   0.16 0.   0.   0.   0.   0.02 0.01 0.08...\n431    [[0.   0.   0.11 0.02 0.03 0.   0.01 0.03 0.  ...\n432    [[0.01 0.   0.11 0.02 0.03 0.   0.01 0.03 0.  ...\n433    [[0.   0.   0.14 0.04 0.06 0.   0.   0.02 0.  ...\n434    [[0.01 0.   0.11 0.02 0.03 0.   0.01 0.02 0.  ...\n435    [[0.   0.   0.11 0.02 0.03 0.   0.01 0.03 0.  ...\n436    [[0.   0.05 0.   0.   0.   0.   0.03 0.   0.09...\n437    [[0.   0.07 0.   0.   0.   0.   0.03 0.   0.08...\n438    [[0.   0.05 0.   0.   0.   0.   0.03 0.   0.1 ...\n439    [[0.   0.07 0.   0.   0.   0.   0.03 0.   0.08...\n440    [[0.   0.   0.11 0.   0.01 0.02 0.01 0.06 0.  ...\n441    [[0.01 0.   0.09 0.   0.01 0.02 0.01 0.08 0.  ...\n442    [[0.02 0.   0.09 0.   0.01 0.03 0.01 0.05 0.  ...\n443    [[0.   0.   0.08 0.   0.01 0.03 0.01 0.07 0.  ...\nName: Pidgey, Length: 444, dtype: object,\n 'Squirtle': 0      [[0.   0.03 0.   0.01 0.   0.   0.04 0.01 0.17...\n1      [[0.   0.01 0.   0.02 0.   0.   0.03 0.02 0.19...\n2      [[0.02 0.   0.02 0.02 0.01 0.02 0.01 0.04 0.01...\n3      [[0.02 0.   0.04 0.   0.02 0.07 0.   0.01 0.  ...\n4      [[0.01 0.   0.04 0.   0.01 0.06 0.   0.04 0.  ...\n5      [[0.01 0.   0.04 0.   0.01 0.1  0.   0.03 0.  ...\n6      [[0.   0.   0.03 0.   0.01 0.09 0.   0.02 0.  ...\n7      [[0.01 0.   0.01 0.03 0.03 0.03 0.03 0.06 0.01...\n8      [[0.01 0.   0.   0.03 0.02 0.   0.02 0.05 0.01...\n9      [[0.01 0.   0.   0.02 0.04 0.04 0.02 0.04 0.02...\n10     [[0.01 0.   0.02 0.03 0.04 0.04 0.03 0.04 0.02...\n11     [[0.   0.09 0.   0.   0.   0.   0.06 0.02 0.04...\n12     [[0.   0.1  0.   0.   0.   0.   0.06 0.02 0.04...\n13     [[0.02 0.   0.02 0.01 0.01 0.05 0.01 0.02 0.01...\n14     [[0.   0.07 0.01 0.   0.   0.   0.04 0.02 0.05...\n15     [[0.   0.1  0.   0.   0.   0.   0.04 0.02 0.04...\n16     [[0.01 0.01 0.05 0.14 0.08 0.   0.01 0.02 0.  ...\n17     [[0.   0.01 0.06 0.15 0.09 0.   0.01 0.03 0.  ...\n18     [[0.   0.01 0.05 0.17 0.09 0.   0.01 0.02 0.  ...\n19     [[0.   0.01 0.06 0.15 0.09 0.   0.01 0.03 0.  ...\n20     [[0.   0.02 0.   0.02 0.   0.01 0.07 0.02 0.11...\n21     [[0.   0.02 0.   0.03 0.   0.01 0.05 0.01 0.12...\n22     [[0.   0.01 0.   0.02 0.   0.01 0.05 0.01 0.11...\n23     [[0.   0.01 0.   0.03 0.   0.01 0.05 0.02 0.11...\n24     [[0.02 0.   0.04 0.06 0.08 0.08 0.01 0.03 0.  ...\n25     [[0.03 0.   0.02 0.02 0.   0.02 0.01 0.09 0.01...\n26     [[0.08 0.   0.01 0.01 0.   0.02 0.01 0.06 0.01...\n27     [[0.06 0.   0.01 0.01 0.   0.   0.   0.05 0.02...\n28     [[0.03 0.   0.02 0.01 0.   0.01 0.01 0.05 0.02...\n29     [[0.03 0.02 0.05 0.02 0.03 0.01 0.03 0.01 0.  ...\n                             ...                        \n710    [[0.   0.   0.16 0.03 0.   0.   0.   0.   0.  ...\n711    [[0.   0.   0.18 0.   0.   0.03 0.   0.   0.  ...\n712    [[0.01 0.   0.01 0.07 0.09 0.03 0.03 0.07 0.01...\n713    [[0.   0.   0.01 0.07 0.1  0.05 0.02 0.08 0.02...\n714    [[0.01 0.   0.05 0.07 0.02 0.02 0.01 0.05 0.  ...\n715    [[0.01 0.   0.04 0.07 0.04 0.01 0.01 0.05 0.  ...\n716    [[0.   0.   0.03 0.05 0.06 0.03 0.01 0.04 0.  ...\n717    [[0.02 0.   0.01 0.05 0.03 0.03 0.01 0.04 0.  ...\n718    [[0.03 0.   0.02 0.01 0.01 0.09 0.02 0.02 0.01...\n719    [[0.   0.01 0.   0.03 0.08 0.01 0.01 0.08 0.01...\n720    [[0.04 0.   0.   0.01 0.06 0.06 0.01 0.06 0.01...\n721    [[0.03 0.   0.   0.02 0.07 0.06 0.01 0.07 0.01...\n722    [[0.   0.01 0.   0.02 0.06 0.01 0.01 0.07 0.01...\n723    [[0.01 0.01 0.04 0.03 0.03 0.02 0.   0.08 0.  ...\n724    [[0.03 0.01 0.05 0.02 0.02 0.02 0.   0.08 0.  ...\n725    [[0.05 0.01 0.02 0.01 0.03 0.03 0.01 0.06 0.  ...\n726    [[0.03 0.01 0.04 0.02 0.04 0.02 0.   0.08 0.  ...\n727    [[0.   0.   0.05 0.08 0.06 0.   0.   0.1  0.  ...\n728    [[0.01 0.   0.06 0.07 0.07 0.   0.   0.11 0.  ...\n729    [[0.02 0.   0.02 0.02 0.01 0.06 0.02 0.02 0.01...\n730    [[0.01 0.   0.07 0.08 0.06 0.   0.   0.1  0.  ...\n731    [[0.   0.   0.05 0.07 0.08 0.   0.   0.09 0.  ...\n732    [[0.   0.02 0.02 0.02 0.   0.03 0.05 0.   0.08...\n733    [[0.   0.01 0.02 0.02 0.   0.03 0.06 0.   0.07...\n734    [[0.   0.01 0.02 0.02 0.   0.03 0.05 0.   0.08...\n735    [[0.   0.02 0.02 0.02 0.   0.03 0.06 0.   0.07...\n736    [[0.   0.08 0.02 0.02 0.   0.   0.07 0.01 0.07...\n737    [[0.   0.05 0.02 0.02 0.   0.   0.06 0.   0.08...\n738    [[0.   0.06 0.03 0.02 0.   0.   0.05 0.   0.07...\n739    [[0.   0.08 0.03 0.02 0.   0.01 0.07 0.   0.08...\nName: Squirtle, Length: 740, dtype: object,\n 'Voltorb': 0      [[0.02 0.22 0.   0.06 0.02 0.   0.02 0.   0.02...\n1      [[0.   0.19 0.   0.06 0.   0.   0.01 0.   0.  ...\n2      [[0.   0.13 0.   0.13 0.   0.02 0.   0.   0.  ...\n3      [[0.   0.1  0.   0.   0.02 0.   0.   0.   0.02...\n4      [[0.   0.12 0.   0.   0.03 0.   0.   0.   0.02...\n5      [[0.   0.12 0.   0.   0.   0.   0.   0.02 0.  ...\n6      [[0.   0.1  0.   0.   0.02 0.   0.   0.02 0.  ...\n7      [[0.   0.02 0.   0.07 0.   0.08 0.   0.05 0.01...\n8      [[0.02 0.02 0.02 0.06 0.01 0.03 0.   0.01 0.02...\n9      [[0.09 0.02 0.   0.05 0.01 0.01 0.   0.01 0.01...\n10     [[0.05 0.02 0.01 0.06 0.01 0.   0.   0.05 0.01...\n11     [[0.   0.04 0.   0.   0.02 0.   0.02 0.02 0.04...\n12     [[0.   0.06 0.   0.   0.   0.   0.02 0.   0.04...\n13     [[0.   0.13 0.   0.11 0.   0.   0.   0.   0.  ...\n14     [[0.   0.02 0.   0.   0.   0.   0.02 0.02 0.02...\n15     [[0.   0.04 0.   0.   0.02 0.   0.02 0.   0.02...\n16     [[0.   0.13 0.   0.   0.   0.   0.   0.01 0.01...\n17     [[0.   0.13 0.   0.   0.   0.   0.   0.03 0.03...\n18     [[0.   0.12 0.   0.   0.   0.   0.   0.01 0.03...\n19     [[0.   0.09 0.   0.   0.   0.   0.01 0.03 0.01...\n20     [[0.02 0.07 0.   0.02 0.   0.   0.   0.   0.  ...\n21     [[0.05 0.12 0.   0.02 0.02 0.   0.   0.   0.  ...\n22     [[0.   0.07 0.   0.07 0.   0.07 0.   0.   0.  ...\n23     [[0.   0.12 0.   0.05 0.   0.05 0.   0.   0.  ...\n24     [[0.   0.01 0.08 0.39 0.03 0.   0.   0.   0.  ...\n25     [[0.02 0.01 0.01 0.08 0.02 0.02 0.01 0.01 0.  ...\n26     [[0.01 0.01 0.02 0.1  0.01 0.02 0.01 0.   0.  ...\n27     [[0.02 0.01 0.03 0.09 0.   0.04 0.   0.   0.  ...\n28     [[0.03 0.01 0.02 0.04 0.   0.05 0.   0.   0.  ...\n29     [[0.   0.07 0.   0.   0.   0.   0.05 0.   0.02...\n                             ...                        \n394    [[0.   0.02 0.03 0.3  0.02 0.   0.01 0.04 0.  ...\n395    [[0.   0.02 0.03 0.3  0.02 0.   0.01 0.04 0.  ...\n396    [[0.   0.02 0.07 0.28 0.03 0.02 0.   0.03 0.  ...\n397    [[0.   0.02 0.06 0.3  0.03 0.02 0.   0.03 0.  ...\n398    [[0.   0.   0.04 0.35 0.04 0.   0.   0.   0.  ...\n399    [[0.   0.   0.04 0.38 0.04 0.   0.   0.   0.  ...\n400    [[0.   0.   0.04 0.38 0.04 0.   0.   0.   0.  ...\n401    [[0.   0.   0.04 0.35 0.04 0.   0.   0.   0.  ...\n402    [[0.02 0.13 0.   0.2  0.   0.02 0.   0.   0.  ...\n403    [[0.02 0.   0.06 0.11 0.   0.   0.01 0.06 0.  ...\n404    [[0.   0.   0.07 0.1  0.02 0.   0.01 0.05 0.  ...\n405    [[0.   0.   0.06 0.1  0.01 0.02 0.01 0.05 0.  ...\n406    [[0.02 0.   0.06 0.1  0.02 0.   0.01 0.06 0.  ...\n407    [[0.02 0.16 0.06 0.08 0.   0.02 0.06 0.   0.02...\n408    [[0.   0.27 0.02 0.08 0.   0.   0.06 0.   0.02...\n409    [[0.   0.2  0.02 0.1  0.   0.   0.08 0.   0.04...\n410    [[0.   0.18 0.   0.08 0.   0.02 0.08 0.   0.  ...\n411    [[0.   0.1  0.   0.   0.02 0.   0.   0.   0.02...\n412    [[0.   0.12 0.   0.   0.03 0.   0.   0.   0.02...\n413    [[0.   0.13 0.   0.22 0.   0.02 0.   0.   0.  ...\n414    [[0.   0.12 0.   0.   0.   0.   0.   0.02 0.  ...\n415    [[0.   0.1  0.   0.   0.02 0.   0.   0.02 0.  ...\n416    [[0.   0.02 0.   0.07 0.   0.08 0.   0.05 0.01...\n417    [[0.03 0.02 0.02 0.06 0.01 0.03 0.   0.01 0.02...\n418    [[0.09 0.02 0.   0.05 0.01 0.01 0.   0.01 0.01...\n419    [[0.05 0.02 0.01 0.06 0.01 0.   0.   0.06 0.01...\n420    [[0.   0.12 0.   0.03 0.   0.   0.01 0.   0.03...\n421    [[0.   0.09 0.   0.03 0.   0.   0.01 0.   0.  ...\n422    [[0.   0.1  0.   0.03 0.   0.   0.01 0.   0.  ...\n423    [[0.   0.13 0.   0.03 0.   0.   0.01 0.   0.  ...\nName: Voltorb, Length: 424, dtype: object}\n"
    }
   ],
   "source": [
    "if RE_CREATE_FEATURE_DICT:\n",
    "        origin_dir = 'Assets/Data_Train'\n",
    "        Hist_Dict = {}\n",
    "        for pkmn in os.listdir(origin_dir):\n",
    "                Hist_Dict[pkmn] = []\n",
    "                current_dir = os.path.join(origin_dir,pkmn)\n",
    "                for k, img in enumerate(os.listdir(current_dir)):\n",
    "                        Hist_Dict[pkmn].append(show_example(os.path.join(current_dir,img), Plot = False))\n",
    "\n",
    "        if CREATE_JSON:\n",
    "                frame_feat = pd.DataFrame(list(Hist_Dict.values()), index = (list(Hist_Dict.keys())))\n",
    "                frame_feat.to_csv(\"features.csv\")\n",
    "else:\n",
    "        frame_feat = pd.read_csv(\"features.csv\").set_index(\"Unnamed: 0\")\n",
    "        Hist_Dict = {k:v for k,v in zip(frame_feat.index.tolist(), \n",
    "                                        [data for data in [i.dropna() for r, i in frame_feat.iterrows()]])}\n",
    "pprint(Hist_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Criar um dataframe para trabalhar melhor com o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-54715900c690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlista_nomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Assets/Data_Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mHist_Dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHist_Dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlista\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   9611\u001b[0m                                       skipna=skipna)\n\u001b[0;32m   9612\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[1;32m-> 9613\u001b[1;33m                             numeric_only=numeric_only)\n\u001b[0m\u001b[0;32m   9614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9615\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3219\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[0;32m   3220\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3221\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m         return delegate._reduce(op=op, name=name, axis=axis, skipna=skipna,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                     \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "if CREATE_FEATURE_DATAFRAME:    \n",
    "    lista = []\n",
    "    lista_nomes = os.listdir('Assets/Data_Train')\n",
    "    for k in Hist_Dict:\n",
    "        x = pd.Series(Hist_Dict[k]).mean()\n",
    "        x = pd.Series(x[0])\n",
    "        lista.append(x)\n",
    "    df_medias = pd.DataFrame(lista, index = lista_nomes)\n",
    "else:\n",
    "    df_medias = pd.DataFrame([[1],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela das frequências relativas médias de cada feature por pokémon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Calculando os valores médios dos dados:\n",
    "### Nesta etapa foi calculado os valores médios dos dados, e em sequência foram aproximados do ponto (0,0), origem do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias = df_medias - (1/40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "normas = (df_medias*df_medias).sum(axis=1)\n",
    "for m in normas.index:\n",
    "    df_medias.loc[m] = df_medias.loc[m]/np.sqrt(normas[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Comparação entre os Pokémons:\n",
    "### Com base nos valores calculados anteriormente, foi criada a tabela seguinte, que mostra o quanto os Pokémons são semelhantes entre si, sendo 1 a semelhança máxima, e -1 o oposto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compara = df_medias.dot(df_medias.transpose())\n",
    "df_compara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos observar que alguns Pokémons possuem muitas semelhanças pois apresentam as mesmas features em abundância (na média).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TOP_N_FOR_FEATURES:    \n",
    "    monstros = []\n",
    "    for feat in range(NUM_CLUSTERS):\n",
    "        monstros.append(sorted(df_medias.nlargest(n=5, columns=[feat]).index) + [feat])\n",
    "    x = sorted(monstros)\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A soma das colunas da tabela anterior mostra quais Pokémons são mais difíceis de distinguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compara.sum(axis = 1).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - \"Machine Learning\" e Classificação:\n",
    "### O método de aprendizado de máquina e classificação utilizado foi o \"Random Forest Classifier\", assim como \"Logistic Regression Classifier\" e \"KNearesNeighbors Classifier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODELS:\n",
    "    # Random forest\n",
    "    randf = RandomForestClassifier(n_jobs=-1, random_state=0, n_estimators = 100)\n",
    "    randf.fit(X_train, y_train)\n",
    "\n",
    "    # KNearestNeighbors\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    neigh.fit(X_train, y_train)\n",
    "\n",
    "    # Logistic regression\n",
    "    logit = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train, y_train)\n",
    "    logit.fit(X_train, y_train);\n",
    "\n",
    "    # Método Nearest Centroid, não utilizado.\n",
    "    # from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "    # clf4 = NearestCentroid()\n",
    "    # clf4.fit(X_train, y_train)\n",
    "\n",
    "    # Método Support Vector Machine, não utilizado.\n",
    "    # from sklearn import svm\n",
    "    # clf5 = svm.SVC(gamma='scale')\n",
    "    # clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abaixo armazenamos os modelos numa estrutura que nos será mais acessível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODELS:\n",
    "    models = {'Random Forest': randf,\n",
    "            'KNearestNeighbors': neigh,\n",
    "            'Losgistic Regression': logit}\n",
    "else:\n",
    "    models = {0:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Análise das classificações realizadas pelo modelo:\n",
    "### A matriz de confusão abaixo mostra em mais detalhes os erros e acertos do classificador. É possível identificar que na maioria das vezes que o modelo falhou, ele identificou erroneamente o Pokémon como sendo uma \"Jigglypuff\" ou um \"Arcanine\".\n",
    "\n",
    "#### Obs: A função *plot_confusion_matrix* abaixo não é de nossa autoria, e sua versão original pode ser encontrada no seguinte endereço: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16,16))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def multi_confusion_mtx(X_test, y_test, model_dict):\n",
    "    for k,v in model_dict.items():\n",
    "        plot_confusion_matrix(y_test, v.predict(X_test), classes=v.classes_,\n",
    "                            title='Normalized confusion matrix for model %s' % k)\n",
    "        plt.show()\n",
    "\n",
    "def precision_at_n(model):\n",
    "    hits, miss = 0, 0\n",
    "    for img, label in zip(TEST_IMG, TEST_LABEL):\n",
    "        rep = representa(vocab, cv2.imread(img))\n",
    "        top3 = pd.Series(model.predict_proba(rep)[0], index = os.listdir('Assets/Data_Test')).nlargest(3)\n",
    "        if label in top3.index.tolist():\n",
    "            hits += 1\n",
    "        else:\n",
    "            miss += 1\n",
    "            \n",
    "    return hits, miss, hits/(hits+miss)\n",
    "\n",
    "def show_guess(path, model):\n",
    "    return pd.Series(model.predict_proba(show_example(path))[0], index = model.classes_).sort_values(ascending = False)\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_CONFUSION_MATRIXES and FIT_MODELS:\n",
    "    multi_confusion_mtx(X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRECISION_AT_N and FIT_MODELS:\n",
    "    pprint({model_name: precision_at_n(model) for (model_name, model) in models.items()})"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}